{"id":2382,"date":"2022-01-24T21:06:11","date_gmt":"2022-01-25T02:06:11","guid":{"rendered":"http:\/\/ccvcl.org\/?page_id=2382"},"modified":"2022-04-23T14:44:16","modified_gmt":"2022-04-23T18:44:16","slug":"csc-471-spring-2022-assignment-4","status":"publish","type":"page","link":"http:\/\/ccvcl.org\/professor-zhigang-zhu\/csc-471-computer-vision-spring-2022\/csc-471-spring-2022-assignment-4\/","title":{"rendered":"CSc 471 Spring 2022 -Assignment 4"},"content":{"rendered":"\n<p>Computer Science \u2013 The City College of New York<br><strong>Computer Vision<br>Assignment 4 ( Deadline: 04\/24 Sunday before midnight <span class=\"has-inline-color has-vivid-red-color\">&#8211; extended for one week to <strong>05\/01 Sunday before midnight<\/strong><\/span>)<\/strong><br>===============================================================<br><strong><em>(Those marked with * are optional for extra credits)<\/em><\/strong><\/p>\n\n\n\n<p>Note:&nbsp; Turn in a PDF document (<strong>in writing; please type<\/strong>) containing a list&nbsp; of your .m files (not the code itself),&nbsp; images showing the results of your experiments, and an analysis of the results.All the writings must be soft copies in print and be sent to Prof. Zhu via email&nbsp;Zhigang Zhu &lt;ds.zhu.ccny@gmail.com&gt;&nbsp;. For the programming part,&nbsp;<strong>send ONLY your source code&nbsp; by email<\/strong>; please don\u2019t send in your images and executable (even if you use C++).&nbsp; You are responsible for the loss of your submissions if you don\u2019t write&nbsp; \u201c<strong>CSC 471 Computer Vision Assignment 4<\/strong>\u201d in the subject of your email. Do write your names and IDs (last four digits) in both both of your report and the code.&nbsp;&nbsp;Please don\u2019t zip your report with your code and other files; send me the report in a separate PDF file. The rest can be in a zipped file.<\/p>\n\n\n\n<hr class=\"wp-block-separator\"\/>\n\n\n\n<p>1.&nbsp; (Stereo- 30 points ) Estimate the accuracy of &nbsp;the simple stereo system (Figure 3 in the lecture notes of stereo vision) assuming that the only source of noise is the localization of corresponding points in the two images. Please derive  the error estimation equation (<strong>10 points<\/strong>) and discuss (<strong>20 points<\/strong>) the dependence of the error in depth estimation of a 3D point as a function of&nbsp;(1) the baseline width, (2) the focal length, (3) stereo matching error, and (4) the depth of the 3D point.<\/p>\n\n\n\n<p>Hint: D = f B\/d; Take the partial derivatives of D with respect to the disparity d.&nbsp;<\/p>\n\n\n\n<p>2. (Motion- 20 points) Could you obtain 3D information of a scene by viewing the scene by using multiple frames of images taken by a camera&nbsp; rotating&nbsp;around&nbsp;its optical center (<strong>5 points<\/strong>)?&nbsp;Discuss why or why not<strong> <\/strong>(<strong>5 points<\/strong>)<strong>.<\/strong>&nbsp;What about&nbsp;translating&nbsp;(moving, not zooming!) the camera along the direction of its optical axis (<strong>5 points)<\/strong>? Explain. (<strong>5 points<\/strong>)<\/p>\n\n\n\n<p>3. (Stereo and Motion \u2013 20 points): (1) Give 5 examples when humans using stereo or motion in daily life or work (<strong>10 points<\/strong>) (2) Give another 5 examples that use computer vision techniques with stereo or motion in real applications (<strong>10 points<\/strong>)<\/p>\n\n\n\n<p>4. (Stereo Programming \u2013 30 points + 10 bonus points) Use the image pair (&nbsp;<a href=\"http:\/\/ccvcl.org\/wp-content\/uploads\/2019\/10\/pic410.png\">Image<\/a><a href=\"http:\/\/ccvcl.org\/home\/computer-vision-fall-2019\/csc-i6716-fall-2019-assignment-4\/pic410.bmp\">&nbsp;1<\/a>,&nbsp;<a href=\"http:\/\/ccvcl.org\/wp-content\/uploads\/2019\/10\/pic430.png\">Image 2<\/a>) for the following exercises.<\/p>\n\n\n\n<p>(1). Fundamental Matrix. \u2013 Design and implement a program that, given a stereo pair, determines at least eight point matches, then recovers the fundamental matrix (<strong>5 points<\/strong>&nbsp;) and the location of the epipoles (<strong>5 points<\/strong>). Check the accuracy of the result by measuring the distance between the estimated epipolar lines and image points not used for the matrix estimation (<strong>5 points<\/strong>). Also, overlay the epipolar lines of control points and test points on one of the images (say Image 1- I already did this in the starting code below). Control points are the correspondences (matches)&nbsp; used in computing the fundamental matrix,&nbsp; and test points are those&nbsp; used to check the accuracy of the computation.<\/p>\n\n\n\n<p>Hint: You can pick up the matches of both the control points and the test points manually. You may use my matlab code (<a href=\"http:\/\/www-cs.engr.ccny.cuny.edu\/~zhu\/CSCI6716-2018s\/Homework\/FmatGUI.m\">FmatGUI.m<\/a>)&nbsp; as a starting point \u2013 where I provided an interface to pick up point matches by mouse clicks. The epipolar lines should be (almost)&nbsp; parallel in this stereo pair. If not, something is wrong either with your code or the point matches. <\/p>\n\n\n\n<p>(2). Feature-based matching. \u2013 Design a stereo vision system to do \u201cfeature-based matching\u201d and explain your algorithm in writing \u2013 what the feature is, how effect it is, and what are the problems (<strong>5 points<\/strong>). The system should have a user interface that allows a user to select a point on the first image, say by a mouse click (<strong>5 points<\/strong>).&nbsp; The system should then find and highlight the corresponding point on the second image, say using a cross hair points).&nbsp;Try to use the epipolar geometry derived from (1) in searching&nbsp; correspondences along epipolar lines (<strong>5 points<\/strong>).&nbsp;<\/p>\n\n\n\n<p>Hint : You may use a similar interface &nbsp;as I did for question (1). <\/p>\n\n\n\n<p>(3) Discussions. Show your results on points with different properties like those in corners, edges, smooth regions, textured regions, and occluded regions that are visible only in one of the images. Discuss for each case, why your vision system succeeds or fails in finding the correct matches (<strong>5 extra points<\/strong>). Compare the performance of your system against a human user (e.g. yourself) who marks the corresponding matches on the second image by a mouse click (<strong>5 extra points<\/strong>).<\/p>\n","protected":false},"excerpt":{"rendered":"<p>Computer Science \u2013 The City College of New YorkComputer VisionAssignment 4 ( Deadline: 04\/24 Sunday before midnight &#8211; extended for one week to 05\/01 Sunday before midnight)===============================================================(Those marked with *&hellip;<\/p>\n","protected":false},"author":3,"featured_media":0,"parent":2279,"menu_order":0,"comment_status":"closed","ping_status":"closed","template":"page-templates\/fullwidth.php","meta":{"footnotes":""},"_links":{"self":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/2382"}],"collection":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/users\/3"}],"replies":[{"embeddable":true,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/comments?post=2382"}],"version-history":[{"count":6,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/2382\/revisions"}],"predecessor-version":[{"id":2521,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/2382\/revisions\/2521"}],"up":[{"embeddable":true,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/2279"}],"wp:attachment":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/media?parent=2382"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}