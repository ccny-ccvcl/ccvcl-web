{"id":412,"date":"2019-01-30T12:53:16","date_gmt":"2019-01-30T17:53:16","guid":{"rendered":"http:\/\/ccvcl.org\/?page_id=412"},"modified":"2019-01-30T13:26:51","modified_gmt":"2019-01-30T18:26:51","slug":"panoramic-virtual-stereo-and-human-tracking-in-a-smart-room","status":"publish","type":"page","link":"http:\/\/ccvcl.org\/panoramic-virtual-stereo-and-human-tracking-in-a-smart-room\/","title":{"rendered":"Panoramic Virtual Stereo and Human Tracking in a Smart Room"},"content":{"rendered":"\n<p><strong>Project Status:<\/strong>\u00a0Complete (Years: 1998 &#8211; 2002)<\/p>\n\n\n\n<h2 class=\"wp-block-heading\">Research Description<\/h2>\n\n\n\n<p>Under the support of the DARPA ITO Software for Distributed Robotics (SDR) and Autonomous Mobile Robot Software (MARS) projects, a panoramic virtual stereo vision approach for localizing 3D moving objects has been developed in the Department of Computer Science at the University of Massachusetts at Amherst. This research focuses on cooperative behavior of robots involving cameras (residing on different mobile platforms) that are aware of each other, and can be composed into a virtual stereo sensor with a flexible baseline in order to detect, track and localize moving human subjects in an environment. In this model, the sensor geometry can be controlled to manage the precision of the resulting virtual sensor. This cooperative stereo vision strategy is particularly effective with a pair of mobile panoramic cameras that have the potential of almost always seeing each other, since each of the panoramic cameras has a full 360-degree field of view (FOV). Once calibrated by &#8220;looking&#8221; at each other, they can view the environment to estimate the 3D structure of the scene by triangulation.<\/p>\n\n\n\n<h2 class=\"wp-block-heading\">Sponsors<\/h2>\n\n\n\n<p><strong>Rome Labs (via DARPA)<\/strong>, EDCS Self Adaptive Software (SAFER AFRL\/IFTD F30602-97-2-0032) &#8211; Tactical Mobile Robots, 07\/98 &#8211; 08\/99<\/p>\n\n\n\n<p><strong>DARPA\/ITO<\/strong>, Mobile Autonomous Robot S\/W (MARS DOD DABT63-99-1-0004) &#8211; A Software Control Framework for Learning Coordinated, Multi-robot Strategies in Open Environments, 05\/03\/00-05\/02\/02<\/p>\n\n\n\n<p><strong>DARPA\/ITO<\/strong>\u00a0Software for Distributed Robotics (SDR DOD DABT63-99- 1-0022) &#8211; Software, Programming, and Run-Time Coordination for Distributed Robotics, 08\/23\/99-11\/30\/01<\/p>\n\n\n\n<p><a href=\"http:\/\/ccvcl.org\/research-projects\/\">Back<\/a><\/p>\n","protected":false},"excerpt":{"rendered":"<p>Project Status:\u00a0Complete (Years: 1998 &#8211; 2002) Research Description Under the support of the DARPA ITO Software for Distributed Robotics (SDR) and Autonomous Mobile Robot Software (MARS) projects, a panoramic virtual&hellip;<\/p>\n","protected":false},"author":1,"featured_media":0,"parent":0,"menu_order":0,"comment_status":"open","ping_status":"closed","template":"","meta":{"footnotes":""},"_links":{"self":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/412"}],"collection":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages"}],"about":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/types\/page"}],"author":[{"embeddable":true,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/comments?post=412"}],"version-history":[{"count":1,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/412\/revisions"}],"predecessor-version":[{"id":413,"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/pages\/412\/revisions\/413"}],"wp:attachment":[{"href":"http:\/\/ccvcl.org\/wp-json\/wp\/v2\/media?parent=412"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}