<!DOCTYPE html>
<html lang="en-US">
	
<!-- Mirrored from ccvcl.org/previous-activities/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 10 Dec 2024 19:23:48 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
		<meta charset="UTF-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="profile" href="http://gmpg.org/xfn/11" />
	<title>Previous Activities &#8211; CUNY Computational Vision and Convergence Laboratory</title>
<meta name='robots' content='max-image-preview:large' />
<link rel="alternate" type="application/rss+xml" title="CUNY Computational Vision and Convergence Laboratory &raquo; Feed" href="../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="CUNY Computational Vision and Convergence Laboratory &raquo; Comments Feed" href="../comments/feed/index.html" />
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/svg\/","svgExt":".svg","source":{"concatemoji":"http:\/\/ccvcl.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.4.2"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udfff","\ud83e\udef1\ud83c\udffb\u200b\ud83e\udef2\ud83c\udfff")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='../wp-includes/css/dist/block-library/style.min1e39.css?ver=6.4.2' type='text/css' media='all' />
<style id='classic-theme-styles-inline-css' type='text/css'>
/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}
</style>
<style id='global-styles-inline-css' type='text/css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}body .is-layout-flex{flex-wrap: wrap;align-items: center;}body .is-layout-flex > *{margin: 0;}body .is-layout-grid{display: grid;}body .is-layout-grid > *{margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
.wp-block-navigation a:where(:not(.wp-element-button)){color: inherit;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
.wp-block-pullquote{font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='bradbury-style-css' href='../wp-content/themes/bradbury-custom/style6b25.css?ver=2.1.4' type='text/css' media='all' />
<link rel='stylesheet' id='academia-icomoon-css' href='../wp-content/themes/bradbury-custom/css/icomoon6b25.css?ver=2.1.4' type='text/css' media='all' />
<script type="text/javascript" src="../wp-includes/js/jquery/jquery.minf43b.js?ver=3.7.1" id="jquery-core-js"></script>
<script type="text/javascript" src="../wp-includes/js/jquery/jquery-migrate.min5589.js?ver=3.4.1" id="jquery-migrate-js"></script>
<script type="text/javascript" src="../wp-content/themes/bradbury-custom/js/superfish.min68b3.js?ver=1" id="jquery-superfish-js"></script>
<script type="text/javascript" src="../wp-content/themes/bradbury-custom/js/jquery.flexslider-min68b3.js?ver=1" id="jquery-flexslider-js"></script>
<link rel="https://api.w.org/" href="../wp-json/index.html" /><link rel="alternate" type="application/json" href="../wp-json/wp/v2/posts/338.json" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="../xmlrpc0db0.php?rsd" />
<meta name="generator" content="WordPress 6.4.2" />
<link rel="canonical" href="index.html" />
<link rel='shortlink' href='../indexbcd6.html?p=338' />
<link rel="alternate" type="application/json+oembed" href="../wp-json/oembed/1.0/embed97a7.json?url=http%3A%2F%2Fccvcl.org%2Fprevious-activities%2F" />
<link rel="alternate" type="text/xml+oembed" href="../wp-json/oembed/1.0/embedc071?url=http%3A%2F%2Fccvcl.org%2Fprevious-activities%2F&amp;format=xml" />
<link rel="icon" href="../wp-content/uploads/2018/11/cropped-ccvcl_logo-32x32.png" sizes="32x32" />
<link rel="icon" href="../wp-content/uploads/2018/11/cropped-ccvcl_logo-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon" href="../wp-content/uploads/2018/11/cropped-ccvcl_logo-180x180.png" />
<meta name="msapplication-TileImage" content="http://ccvcl.org/wp-content/uploads/2018/11/cropped-ccvcl_logo-270x270.png" />
</head>

<body class="post-template-default single single-post postid-338 single-format-standard custom-background wp-custom-logo wp-embed-responsive page-sidebar-left site-page-noslideshow">


<div id="container">

	<a class="skip-link screen-reader-text" href="#site-main">Skip to content</a>
	<div class="site-wrapper-all site-wrapper-boxed">

		
		<header id="site-masthead" class="site-section site-section-masthead">
			<div class="site-section-wrapper site-section-wrapper-masthead">
				<div id="site-logo"><a href="../index.html" class="custom-logo-link" rel="home"><img width="3000" height="3000" src="../wp-content/uploads/2018/11/ccvcl_logo.png" class="custom-logo" alt="Logo for CUNY Computational Vision and Convergence Laboratory" decoding="async" fetchpriority="high" /></a>			</div><!-- #site-logo --><!-- ws fix 
			--><div id="site-section-primary-menu">
									</div><!-- #site-section-primary-menu -->
			</div><!-- .site-section-wrapper .site-section-wrapper-masthead -->
		</header><!-- #site-masthead .site-section-masthead -->
		
<main id="site-main">

	
	<div class="site-page-content">
		<div class="site-section-wrapper site-section-wrapper-main clearfix">

			<div class="site-column site-column-content"><div class="site-column-wrapper clearfix"><!-- .site-column .site-column-1 .site-column-aside --><p class="entry-tagline"><span class="post-meta-span"><time datetime="2019-01-29" pubdate>January 29, 2019</time></span><span class="post-meta-span category"><a href="../category/uncategorized/index.html" rel="category tag">Uncategorized</a></span></p><!-- .entry-tagline --><h1 class="page-title">Previous Activities</h1><div class="entry-content">
<p><strong>November 09, 2021.</strong> Lab Member Steven Alsheimer, a master student in the Data Science Program at the Graduate Center, will be a Data Scientist with Canon, starting by the end of November. Congratulations!</p>



<p><strong>November 1, 2021.</strong> Lab Members  Arber Ruci and Jin Chen  are leading a startup <a href="https://nearabl.com/">Nearabl</a>, a spin-off from the <a href="../smart-and-accessible-transportation-hub/index.html">NSF PFI Project SAT-Hub</a>. Read more in <a href="https://finance.yahoo.com/news/nearabl-app-created-blind-moving-204000360.html">a news item in Yahoo Finance</a>.  </p>



<p><strong>September 14, 2021</strong>, CCNY Places 3rd In International Overhead Imagery Hackathon [<a href="https://www1.cuny.edu/mu/forum/2021/09/27/ccny-places-3rd-in-international-overhead-imagery-hackathon/">CUNY Newswire</a>] [<a href="https://www.ccny.cuny.edu/news/ccny-places-3rd-international-overhead-imagery-hackathon">CCNY News</a>]</p>



<p><strong>August 06, 2021</strong>. Professor Hao Tang received an NSF CISE-MSI Grant (PI: Hao Tang; Co-PIs: Zhigang Zhu, William H Seiple) [<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2131186&amp;HistoricalAwards=false">NSF Summary</a>] [<a href="https://www1.cuny.edu/mu/forum/2021/09/10/bmcc-led-research-on-virtual-guide-dog-for-visually-impaired-people-receives-500000-nsf-grant/">CUNY Wire</a>]</p>



<p><strong>June 03, 2021</strong>. Professor Zhigang Zhu and DSE master student Jin Chen were featured on <em><strong><a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__futurumcareers.com_using-2Dai-2Dand-2Dcomputer-2Dscience-2Das-2Da-2Dforce-2Dfor-2Dsocial-2Dgood&amp;d=DwMFAg&amp;c=4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&amp;r=KQbVpoJK3r1M9kJrt4YwwzaPui7fLvZ_tDOejpdiKf8&amp;m=A-ap_-sSieIIK6HSXEb0OMsqaHu0n5Q1MZw8xABVV-Q&amp;s=ZJRUXCAtWExz3kHB9B0H14XUH75U3IviH6uTundih20&amp;e=">Futurum</a></strong>, a magazine and online platform aimed at inspiring young people to follow a career in the sciences, research and technology.</em></p>



<p><strong>May 13, 2021.</strong> Mr. Xingye (Alex) Li. <a href="../wp-content/uploads/2023/08/SnapshotNet__Self_supervised_Feature_Learning_for_Point_Cloud_Data_Segmentation_Using_Minimal_Labeled_Data-Alex-Li.pdf">SnapshotNet: Self-supervised Feature Learning for Point Cloud Data Segmentation Using Minimal Labeled Data. Master Thesis</a> (Advisor: Professor Zhigang Zhu), Data Science and Engineering, The City College of New York. Congratulations!</p>



<p><strong>May 1, 2021</strong>. <strong>AFOSR STTR Phase I (subaward via Intelligent Fusion Technology, Inc</strong>.), Robust Multi-View Target Attitude Determination Using Models, Multi-Cues and Machine Learning.  Duration: 05/01/2021-04/31/2022</p>



<p><strong>January 13, 2021</strong>. <strong>AFOSR Grant</strong> (<strong>Award <strong>#FA9550-21-1-0082</strong></strong>) on <em>Dynamic data driven applications systems with multimodal sensing, collaborative perception and deep computing</em> [<a href="http://www1.cuny.edu/mu/forum/2021/01/13/three-year-air-force-grant-engages-ccny-harlem-students-in-advanced-sensing-research/">CUNY&nbsp;Newswire</a>] [<a href="https://www.ccny.cuny.edu/news/three-year-air-force-grant-engages-ccny-harlem-students-advanced-sensing-research">CCNY News</a>] [<a href="https://www.linkedin.com/feed/update/urn:li:activity:6755317102493667328/">GSOE LinkedIn</a>] [<a href="https://twitter.com/CityCollegeNY/status/1349397923675729923">CCNY Tweet</a>]</p>



<p><strong>November 18, 2020</strong>. Check this out: <a href="http://www.guide2research.com/">Guide to Research</a>.</p>



<p><strong>September 2, 2020.</strong> Two students in Professor Zhu&#8217;s <a href="../professor-zhigang-zhu/computer-vision-and-image-processing-spring-2020/index.html">Computer Vision and Image Processing</a> Class at the CUNY Graduate Center in Spring 2020 are the winners of this year’s student poster competition&nbsp;(with a $1000 scholarship each) of the GC CS and DS programs, based on their course projects. <em><a href="../wp-content/uploads/2020/09/Winner-Announcement-Best-Poster-Competition.png">“Social Distancing Using Deep Learning and 3D Computer Vision” By Bilal AbdulRahman and “Structure from Motion with Space Carving and MaskRCNN Segmentation” by Steven Alsheimer.</a></em> Congratulations!</p>



<p><strong>May, 2020.</strong> Mr. Yaohua Chang. <a href="../wp-content/uploads/2023/08/iASSIST_Capstone_Thesis_Yaohua_2020Final-version-OLD.pdf">Multimodal Data Integration for Real-Time Indoor Navigation Using a Smartphone.</a> Master Thesis (Advisor: Professor Zhigang Zhu), Data Science and Engineering, The City College of New York. Congratulations!</p>



<p><strong>August 19, 2019</strong>.&nbsp;Mr. GREGORY OLMSCHENK successfully defended his PhD thesis:&nbsp;<a href="../olmschenk-dissertation/index.html">SEMI-SUPERVISED REGRESSION WITH GENERATIVE ADVERSARIAL NETWORKS USING MINIMAL LABELED DATA – CRITICAL ISSUES, NETWORKS BEHAVIORS AND APPLICATIONS</a>. &nbsp;<a href="../wp-content/uploads/2019/08/OlmschenkDefenseSummarySlides-2019-.pdf">Here are a few summary slides</a>. Congratulations!</p>



<p><strong>May 2019.</strong>  Ms. Ling Zhang.  <a href="../wp-content/uploads/2023/08/Ling-Zhang-Thesis.pdf">Unsupervised Feature Learning for Point Cloud by Contrasting and Clustering with Graph Convolutional Neural Network</a>, Master Thesis (Advisor: Professor Zhigang Zhu), Computer Engineering, The City College of New York. Congratulations!</p>



<p><strong>October 24, 2018.&nbsp;</strong> <strong>Smart&nbsp; and Accessible Transportation Hub Project in the News (<a href="http://www1.cuny.edu/mu/forum/2018/10/24/ccny-partners-develop-gps-type-app-for-the-visually-impaired/">CUNY Newswire</a> | <a href="https://www.ccny.cuny.edu/news/ccny-partners-develop-gps-type-app-visually-impaired">CCNY News</a>).</strong> More details please see <a href="../smart-and-accessible-transportation-hub/index.html"> SAT-Hub Page.</a></p>



<p><strong>October 16, 2018.</strong>  Professor Zhigang Zhu was an invited speaker at PANEL: CROSSMODAL LEARNING IN HUMAN AND ROBOTS, University of Hamburg and the German Center for Research and Innovation (GCRI) in New York City, 16 OCTOBER 2018, GRAND CENTRAL TECH, 355 MADISION AVE, NEW YORK. The title of his presentation was <em>Multimodal Human-Machine Perception and Assistive Technology.</em></p>



<p><strong>April 25, 2018.</strong> Our Two Capstone CREATE Teams in 2017-2018:<strong> ASSIST </strong>(Assistive Sensor Solution for Independent and Safe Travel, by Vishnu Nair and Manjekar Budhai) was in the <strong> <a href="http://spectrumlocalnews.com/nys/capital-region/news/2018/04/25/college-students-showcase-technology-to-help-disabled-workers-#">Spectrum Local News</a> </strong>(Manjekar talking  at the meeting while Vishnu testing in the field), and <strong> AVR4ASD </strong>(Augmented and Virtual Reality for  Individuals with Autism Spectrum Disorder, by Xinyu Xiong,  Rafael Li Chen and Yuxuan Huang) won the <strong> <a href="http://www-cs.engr.ccny.cuny.edu/~zhu/AVR4ASD-CREATE-2nd-place-prize-2018.pdf">Second Place Prize of the CREATE Competition</a> </strong>(in the picture: Rafael, Xinyu and Prof. Zhigang Zhu). This is a partnership with Ms. Celina Canvalluzzi, Director of Day Services at Goodwill Industries of  Greater New York and Northern New Jersey.; More details please see<a href="https://www.ccny.cuny.edu/news/ccny-students-create-new-ways-eliminate-workplace-barriers-people-disabilities"> a news release at CCNY.</a>

<a href="https://www.ccny.cuny.edu/news/ccny-students-create-new-ways-eliminate-workplace-barriers-people-disabilities"> </a></p>



<p><strong>December 15, 2017</strong> Ms Farnaz Abtahi successfully defended her PhD thesis:  <a href="../wp-content/uploads/2023/08/Farnaz-Abtahi-Thesis_Final_Revised-zz.pdf">MULTIMODAL SENSING AND DATA PROCESSING FOR SPEAKER AND EMOTION RECOGNITION USING DEEP LEARNING MODELS WITH AUDIO, VIDEO AND BIOMEDICAL SENSORS</a> (Advisors: Professor Zhigang Zhu, Professor Tony Ro). Congratulations!</p>



<p><strong>May 26, 2017</strong> Mr. Wei LI successfully defended his PhD thesis: <a href="../wp-content/uploads/2023/08/Thesis_Wei_Revision_zz.pdf">DEEP LEARNING BASED FACIAL COMPUTING &#8211; DATA, ALGORITHMS AND APPLICATIONS</a> (Advisor: Professor Zhigang Zhu). Congratulations!</p>



<p><strong>March 1, 2017</strong>&nbsp;The Visual Computing Lab won a&nbsp;<strong>Department of Homeland Security Follow-On of Summer Research Team For MSIs (via ORAU DE-SC0014664),</strong>&nbsp;Learning, Visualization and Utilization of Crowd Analytics for Security and Navigation Using 3D Semantic Models, PI:&nbsp;<strong>Zhigang Zhu</strong>&nbsp;(with students: Greg Olmschenk and Vishnu Nair); Total Cost: $126,193 (DHS $45,000 + Rutgers (Jie Gong) $18,865 + CCNY $62,328); Duration: 12 months (03/01/2017-02/28/2018)</p>



<p><strong>January 03, 2017</strong> Mr. Feng Hu successfully defended his PhD thesis: <a href="../wp-content/uploads/2023/08/Feng_HU-Dissertation_Write_Up.pdf">VISION-BASED ASSISTIVE INDOOR LOCALIZATION</a> (Advisor: Professor Zhigang Zhu). Congratulations!</p>



<p><strong>Fall 2016 &#8211; Spring 2017</strong>&nbsp;Four student teams in the joint senior design class of Prof. Zhu (CS) and Prof. Jizhong Xiao (EE) won&nbsp;<strong>NYSID CREATE (Cultivating Resources for Employment with Assistive TEchnology) Grants</strong>&nbsp;for projects on improving employment for people with Autism Spectrum Disorder (ASD): CCNY SmartCane for assistive navigation for the blind, Panoramik for finding articles for the blind, VR4ASD for training people with ASD in taking trains, and The Fourth Dimension for task management of people with ASD.</p>



<p><strong>September 1, 2016</strong>&nbsp;Prof. Zhigang Zhu is Co-PI of an&nbsp;<strong>Air Force Research Laboratory award (Award #FA8650-13-C-5800)</strong>&nbsp;under the&nbsp;<strong>Research Collaboration Program (RCP),</strong>&nbsp;&#8220;Multimodal Collaborative Sensing and Identification Using Deep Learning for Intelligence, Surveillance and Reconnaissance (ISR) Applications&#8221; (PI: Jie Wei; Co-PI: Zhigang Zhu), 9/1/2016 to 9/30/2018, renewable up to five years.</p>



<p><strong>August 30, 2016</strong> Mr. Wai L. Khoo successfully defended his PhD thesis: <a href="../wp-content/uploads/2023/08/WaiKhoo_Dissertation_Final.pdf">GIVE‐ME: GAMIFICATION IN VIRTUAL ENVIRONMENTS FOR MULTIMODAL EVALUATION – A FRAMEWORK</a> (Advisor: Professor Zhigang Zhu). Congratulations!</p>



<p><strong>Fall 2015 &#8211; Spring 2016</strong>&nbsp;Three student teams in the joint senior design class of Prof. Zhu (CS) and Prof. Jizhong Xiao (EE) won&nbsp;<strong>NYSID CREATE (Cultivating Resources for Employment with Assistive TEchnology) Grants</strong>&nbsp;for projects on improving employment for people with Autism Spectrum Disorder (ASD): CuraWatch for task management and monitoring, Green Jacket for ordering meals, and QR Navigation for indoor navigation.</p>



<p><strong>May 02, 2016</strong>&nbsp;Three members of the City College Visual Computing Lab directed by Prof. Zhigang Zhu have been accepted to the Summer Research Team Program for Minority Serving Institutions at the DHS CCICADA at Rutgers, working on a Collaborative Vision Approach with Semantic 3D Scene Models for Scalable Crowd Behavior Analysis and Navigation Support. The team members are Dr. Zhigang Zhu (Professor of Computer Science), Greg Olmschenk (PhD student at CUNY Graduate Center), and Vishnu Nair (an undergraduate student in Computer Engineering), and the CCICADA advisor is Prof. Jie Gong at Rutgers.</p>



<p><strong>March 29, 2016</strong>&nbsp;Prof. Zhigang Zhu gave an invited talk Entrepreneurship: From the Perspective of a Research Mentor, at the Innovation &amp; Business Concepts Forum, Entrepreneurial Concept Competition (ECC) Workshop, NYC Alliance.</p>



<p><strong>March 16, 2016</strong>&nbsp;Prof. Zhigang Zhu gave an invited talk at Cornell Tech, New York City, on Multimodal and Alternative Perception for Assisting People in Need.</p>



<p><strong>November 12, 2015</strong>&nbsp;Prof. Zhigang Zhu gave a talk Multimodal and Alternative Perception with Human-Machine Collaboration, in the CCICADA-CRG Research Talk, DHS CCICADA HQ in Piscataway, NJ.</p>



<p><strong>October 25, 2015</strong>&nbsp;A team of Visual Computing Lab members (Z. Zhu, H. Tang, E. Molina, W. L. Khoo, F. Hu, W. Li) attended STEMFest, Highland View Academy, with demonstrations and a panel talk: Emerging Technologies of Mobile Computing and Gaming for Helping the Blind.</p>



<p><strong>May 22, 2015</strong>&nbsp;Professor Zhu and PhD student Greg Olmschenk give a talk on Multimodal and Alternative Perception for Man-Machine Collaboration, Accessibility Research Group, IBM Research-Tokyo.</p>



<p><strong>March 27, 2015</strong>&nbsp;CcvcL members (Z. Zhu, H. Tang, E. Molina and W. L. Khoo) organized a Creativity &amp; Innovation Workshop, Accessible Games, Virtual Reality and Wearable Devices for People Who Are Visually Impaired, The 8th Annual CCVIP Annual Employment and Visual Impairment Conference on Policy &amp; Practice: “Make It Happen”.</p>



<p><strong>March 12, 2015</strong>&nbsp;Professor Zhu Zhu gave an invited talk onResearch and Education on Assistive Technologies for the Blind, in the New Dimensions Lecture Series at Brooklyn Technical High School.</p>



<p><a href="https://www.ccny.cuny.edu/news/ccny-students-create-new-ways-eliminate-workplace-barriers-people-disabilities"><strong>May 17, 2015</strong> Vista Wearable Inc. is featured in the Crains New York Business. Here&#8217;s article </a><a href="http://www.crainsnewyork.com/article/20150517/TECHNOLOGY/150519896/its-all-wearable-tech-but-will-people-want-to-wear-it">(link)</a> Here&#8217;s the feature <a href="http://www.crainsnewyork.com/gallery/20150517/FEATURES01/516009999/8">(link)</a></p>



<p><strong>May 15, 2015</strong> Mr. Edgardo Molina successfully defended his PhD thesis: <a href="../wp-content/uploads/2023/08/edgardo-molina-thesis-final.pdf">PANORAMA GENERATION FOR STEREOSCOPIC VISUALIZATION OF LARGE SCALE</a> (Advisor: Professor Zhigang Zhu). Now is the lead instructor for CUNY Tech Prep, after being CEO and Co-Founder of Vista Wearable, Inc. Congratulations!</p>



<p><strong>April 30, 2015</strong>&nbsp;A CS/CpE/EE Joint Senior Design Team won the 2015 Social Innovation Prize ($30K) from the Zahn Innovation Center. Project Title: HAST: Health and Support Technology for Families using Open Source Wearable Devices. Team members (Joint Senior Design Class Students): Benjamin Tan (EE), Bin Xu (EE), Ni Yao (CpE) and Xue Bin Zhao (CS). Mentors: Professors Jizhong Xiao and Zhigang Zhu.</p>



<p><strong>April 9, 2015</strong>&nbsp;Three members of the City College Visual Computing Lab directed by Prof. Zhigang Zhu have been accepted to the Summer Research Team Program for Minority Serving Institutions at the DHS CCICADA at Rutgers. They are Dr. Hao Tang (assistant professor at BMCC, PhD graduate from Prof. Zhu’s group), Greg Olmschenk (Prof. Zhu’s current PhD student), and David Zeng (an undergraduate student in Prof. Zhu’s Data Structures class).</p>



<p><strong>Feb 21, 2015</strong>&nbsp;Mr. Harith Morgan, a high school student at Brooklyn Tech, won the 2015 REM Best Poster Award during the 2015 EMERGING RESEARCHERS NATIONAL (ERN 2015) CONFERENCE IN STEM in Washington DC. Harith was a research participant in the 2014-2015 EFRI-REM Summer Research Program at CCNY.</p>



<p><strong>Jan 1, 2015</strong>&nbsp;City College will continue the NSF EFRI Research Experience and Mentoring (EFRI-REM) program for the fourth year on Multimodal Alternative Perception for Visually Impaired People (MAP-4-VIP). This is a supplement to the existing $2M NSF EFRI-M3C grant, with $100K, $120K, $100K and $100K for years 2012, 2013, 2014 and 2015 respectively, to attract, support and train underrepresented students in cutting-edge research in STEM fields:&nbsp;<a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1137172">(link)</a></p>



<p><strong>March 20, 2014</strong>&nbsp;Looking for applicants to the&nbsp;<a href="../_khoo/REM2014.1.html">NSF EFRI-REM 2014 program.</a></p>



<p><strong>May 20, 2013</strong> Professor Zhigang Zhu received <a href="http://www-cs.engr.ccny.cuny.edu/~zhu//letter-president-award-for-excellence-2013.pdf">President’s Award for Excellence,</a> The City College of New York, in the inaugural year of the President&#8217;s Awards.</p>



<p><strong>May 18, 2013</strong>&nbsp;Congratulations to Mr. Wai Khoo on receiving GC Provost&#8217;s Digital Incubator Grant of $1,000.</p>



<p><strong>May 18, 2013</strong>&nbsp;Congratulations to Mr. Greg Olmschenk on receiving PSC-CUNY award of $12,000, with Prof. Zhigang Zhu.</p>



<p><strong>May 18, 2013</strong>&nbsp;Congratulations to Dr. Hao Tang on receiving PSC-CUNY award of $6,000.</p>



<p><strong>May 04, 2013</strong>&nbsp;City College will continue the NSF EFRI Research Experience and Mentoring (EFRI-REM) program for the second year on Multimodal Alternative Perception for Visually Impaired People (MAP-4-VIP). PIs: Zhigang Zhu, Tony Ro and YingLi Tian. This is supplement to the existing $2M NSF EFRI-M3C grant, with $100K and $120K for year 1012 and year 2013, respectively, to attract, support and train underrepresented students in cutting-edge research in STEM fields:<a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1137172">http://www.nsf.gov/awardsearch/showAward?AWD_ID=1137172</a></p>



<p><strong>March 19, 2013</strong>&nbsp;Professors Zhigang Zhu (CS), Yingli Tian (EE) and Tony Ro (Psy) are co-chairs of the IEEE Workshop on Multimodal and Alternative Perception for Visually Impaired People (MAP4VIP), July 15th, 2003, San Jose, USA, in conjunction with ICME 2013.&nbsp;<a href="http://www-cs.engr.ccny.cuny.edu/~zhu/MAP4VIP/">http://www-cs.engr.ccny.cuny.edu/~zhu/MAP4VIP/</a>&nbsp;This workshop is financially sponsored by NSF (detail:<a href="http://nsf.gov/awardsearch/showAward?AWD_ID=1327236">http://nsf.gov/awardsearch/showAward?AWD_ID=1327236</a>&nbsp;), Microsoft Research and Grove School of Engineering at CCNY.</p>



<p><strong>Feb 11, 2013</strong>&nbsp;Professors Zhigang Zhu (CS), Jizhong Xiao (EE)and Tony Ro (Psy) won a three-year grant from National Collegiate Inventors and Innovators Alliance (NCIIA) Course and Program for strengthening interdisciplinary undergraduate senior designs. The theme is “Human and Machine Intelligence &#8211; Perception, Computation and Action”, and the grant period is June 1, 2013 to August 31, 2016&nbsp;<a href="http://nciia.org/node/1990">http://nciia.org/node/1990</a></p>



<p><strong>December 06, 2012</strong> Mr. Hao Tang successfully defensed his PhD thesis: 3D SCENE MODELING AND UNDERSTANDING FROM IMAGE SEQUENCES (Advisor: Professor Zhigang Zhu). Now he is an Assistant Professor at the Borough of Manhattan Community College, The City University of New York. Congratulations!</p>



<p><strong>November 06, 2012</strong> Mr. Tao Wang successfully defensed his PhD thesis: <a href="../wp-content/uploads/2023/08/PhD_Dissertation_Tao_Wang-draft.pdf">AN ADAPTIVE AND INTEGRATED MULTIMODAL SENSING AND PROCESSING FRAMEWORK FOR LONG RANGE MOVING OBJECT DETECTION AND CLASSIFICATION</a> (Advisor: Professor Zhigang Zhu). Now he is a Senior Software Engineer at BAE Systems. Congratulations!</p>



<p><strong>September 2012</strong>&nbsp;Mr. Edgardo Molina received the Khan and Lyons Scholarship for Ph.D. Student in the Grove School of Engineering, The City College of New York. Congratulations!</p>



<p><strong>August 27, 2012</strong>&nbsp;PhD students Ms Farnaz Abtahi, Mr. Feng Hu and Mr. Martin Goldberg joined the City College Visual Computing Lab. Welcome!</p>



<p><strong>August 17, 2012</strong>&nbsp;Professor Jizhong Xiao (EE) and Professor Zhigang Zhu (CS) won a 5-year NSF grant developing and running a joint Senior Design Program on Assistive Technology to Aid Visually Impaired People in CS, CpE and EE.&nbsp;<a href="http://www.nsf.gov/awardsearch/showAward?AWD_ID=1160046">http://www.nsf.gov/awardsearch/showAward?AWD_ID=1160046</a></p>



<p><strong>August 7, 2012</strong>&nbsp;Prof. Zhigang Zhu named the&nbsp;<strong>Herbert G. Kayser Chair Professor of Computer Science</strong>&nbsp;in the Grove School of Engineering, the City College of New York. This is a recognition of the academic achievement of the entire CcvcL team.</p>



<p><strong>August 1, 2012</strong>&nbsp;Prof. Guihua Liu from Southwest University of Science and Technology (China) joined the Lab as a visiting research scholar. Welcome!</p>



<p><strong>June 19, 2012</strong>&nbsp;CcvcL won the&nbsp;<a href="http://nsf.gov/awardsearch/showAward.do?AwardNumber=1243737">NSF I-Corps Award: Transforming 2D Video into an Interactive 3D Viewing Experience</a>&nbsp;(PI: Zhigang Zhu, EL: Edgardo Molina, IMs: Peter Chang and John Blaho)</p>



<p><strong>June 4, 2012</strong>&nbsp;The new&nbsp;<a href="http://www.nsf.gov/pubs/2012/nsf12052/nsf12052.jsp">NSF EFRI-REM</a>&nbsp;program on Multimodal Alternative Perception for Visually Impaired People (MAP-4-VIP) at CCNY started.&nbsp;<em>PIs:</em>&nbsp;Zhigang Zhu, Tony Ro and YingLi Tian.&nbsp;<em>PhD Student Coordinators:</em>&nbsp;Wai L. Khoo, Edgardo Molina, Hao Tang.&nbsp;<em>PhD Student Mentors:</em>&nbsp;Lei Ai, Psy, Wai L. Khoo, CS, Edgardo Molina, CS, Hao Tang, CS, Tao Wang, CS, Kelly Webster, Psy, Xiaodong Yang, EE, Chucai Yi, EE&nbsp;<em>Research Assistants:</em>&nbsp;Alpha Diallo, CS, Martin Goldberg, CS, Joey Knapp, CS, Carol Mazuera, EE, Frank Palmer, CpE and Math, Jessica Vargas, CS and Psy, Margaret A. Vincent, Psy.&nbsp;<em>Observers:</em>Christine Bharosi, Kalah Dolmen, Jim Waters (NYISE), Ben Humphreys (CCNY), Joey Pan (Bronx Science).&nbsp;<strong>This is a truly mulch-disciplinary team work with a pipeline training model.</strong></p>



<p><strong>May 3, 2012</strong>&nbsp;Our 2011-2012 Capstone Team V.I.S.T.A. Won the&nbsp;<a href="http://www1.cuny.edu/mu/forum/2012/05/18/ccny-announces-winner-of-50000-kaylie-prize-for-entrepreneurship/">$50000 Kaylie Prize</a>&nbsp;(See also The City College&nbsp;<a href="http://entrepreneurship.ccny.cuny.edu/kaylieprize">Kaylie Prize for Entrepreneurship</a>&nbsp;). The team, &#8220;VISTA Wearable,&#8221; includes four senior computer engineering majors – Daniel Zuleta, Frank Palmer, Cindy Rodriguez, and Javier Montesino – and doctoral student in psychology, Lei Ai. Professor of Computer Science Zhigang Zhu and Professor of Psychology Tony Ro advised the team.</p>



<p>We are looking for highly motivated PhD student as a research assistant working on multimodal sensor design and machine learning. For more information, please visit&nbsp;<a href="http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=1137172">an abstract</a>&nbsp;of the NSF EFRI Research Award, and&nbsp;<a href="http://www.ccny.cuny.edu/news/CCNY-led-Research-Could-Lead-to-Wearable-Sensors-for-Blind.cfm">a news post</a>&nbsp;about the project. And contact&nbsp;<a href="http://www-cs.ccny.cuny.edu/~zhu/">Dr. Zhigang Zhu.</a></p>



<p>Professor Zhigang Zhu as PI, along with Co-PI&#8217;s Tony Ro (Psychology, CCNY), Ying Li Tian (EE, CCNY), Kok-Meng Lee (Georgia Tech) and Boris Prilutsky (Georgia Tech) have been awarded a 4 year NSF EFRI award under the topic Man, Machine and Motor Control (M3C) for their proposal: Mobility Skill Acquisition and Learning through Alternative and Multimodal Perception for Visually Impaired People.<a href="http://www.nsf.gov/awardsearch/showAward.do?AwardNumber=1137172">[Read more]</a></p>



<p>Professor Zhigang Zhu with Professor Jizhong Xiao have received a NCIAA grant for a senior design course on: Wearable Multimodal Wayfinding Techniques for Blind and Visually Impaired People.&nbsp;<a href="http://nciia.org/node/1619">[Read more]</a></p>



<p>Professor Zhigang Zhu has been selected as a Faculty Fellow for the 2011 Air Force Summer Faculty Fellowship Program (SFFP). He will bring two PhD students (Mr. Edgardo Molina and Mr. Tao Wang) to work with him at the Air Force Research Laboratory.</p>



<p>Two Master students, Mr. Jian-Hong Li, Mr. Martin Goldberg and one undergraduate student Mr. Frank Palmer joined the Visual Computing Laboratory. Welcome!</p>



<p>PhD student Mr. Hao Tang just returned from an internship at SRI International Sarnoff. Welcome back!</p>



<p>PhD student Wai L. Khoo is teaching CS212: Data Structures during the Summer 2011 semester.</p>



<p>Mr. Jiang-Hong Li has been selected as a summer intern in 2011 at IBM Research China. Congratulations!</p>



<p>PhD students Tao Wang and Hao Tang successfully passed their second exams (literature reviews). Congratulations!</p>
</div><!-- .entry-content --></div><!-- .site-column-wrapper .clearfix --></div><!-- .site-column .site-column-content --><div class="site-column site-column-aside">

			<div class="site-column-wrapper clearfix">

				<div class="widget_text widget widget_custom_html clearfix" id="custom_html-2"><div class="textwidget custom-html-widget"><style>
.navigation li a {
	display: block;
	padding-top: 10px;
	padding-bottom: 10px;
	padding-left: 10px;
	margin-bottom: 2px;
	border: 1px solid #000000;
	border-left: 5px solid #590F6E;
	text-decoration: none;
}

.navigation {
	padding: 0px;
	margin: 0px;
	list-style: none;
}
</style>
<ul class="navigation">
<li><a href="../index.html">Home</a></li>
<li><a href="../people/index.html">People</a></li>
<li><a href="../research-projects/index.html">Research</a></li>
<li><a href="../publications/index.html">Publications</a></li>
<li><a href="../courses/index.html">Courses</a></li>
</ul></div></div><div class="widget widget_meta clearfix" id="meta-2"><p class="widget-title">Meta</p>
		<ul>
						<li><a href="../wp-login.html">Log in</a></li>
			<li><a href="../feed/index.html">Entries feed</a></li>
			<li><a href="../comments/feed/index.html">Comments feed</a></li>

			<li><a href="https://wordpress.org/">WordPress.org</a></li>
		</ul>

		</div>
			</div><!-- .site-column-wrapper .clearfix -->

		</div><!-- .site-column .site-column-aside -->
		</div><!-- .site-section-wrapper .site-section-wrapper-main -->
	</div><!-- .site-page-content -->

	
</main><!-- #site-main -->
	

		<div id="site-footer-credit">
			<div class="site-section-wrapper site-section-wrapper-footer-credit">
				<p class="site-credit">Copyright &copy; 2024 CUNY Computational Vision and Convergence Laboratory</p>
						<p class="academia-credit">Theme by <a href="https://www.academiathemes.com/" rel="nofollow designer noopener" target="_blank">AcademiaThemes</a></p>			</div><!-- .site-section-wrapper .site-section-wrapper-footer-credit -->
		</div><!-- #site-footer-credit -->

	</div><!-- .site-wrapper-all .site-wrapper-boxed -->

</div><!-- #container -->

<script type="text/javascript" src="../wp-content/themes/bradbury-custom/js/bradbury6b25.js?ver=2.1.4" id="bradbury-scripts-js"></script>
	<script>
	/(trident|msie)/i.test(navigator.userAgent)&&document.getElementById&&window.addEventListener&&window.addEventListener("hashchange",function(){var t,e=location.hash.substring(1);/^[A-z0-9_-]+$/.test(e)&&(t=document.getElementById(e))&&(/^(?:a|select|input|button|textarea)$/i.test(t.tagName)||(t.tabIndex=-1),t.focus())},!1);
	</script>
	</body>

<!-- Mirrored from ccvcl.org/previous-activities/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 10 Dec 2024 20:20:07 GMT -->
</html>