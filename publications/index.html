<!DOCTYPE html>
<html lang="en-US">
	
<!-- Mirrored from ccvcl.org/publications/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 10 Dec 2024 20:24:08 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<head>
		<meta charset="UTF-8" />
		<meta http-equiv="X-UA-Compatible" content="IE=edge" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="profile" href="http://gmpg.org/xfn/11" />
	<title>Publications &#8211; CUNY Computational Vision and Convergence Laboratory</title>
<meta name='robots' content='max-image-preview:large' />
<link rel="alternate" type="application/rss+xml" title="CUNY Computational Vision and Convergence Laboratory &raquo; Feed" href="../feed/index.html" />
<link rel="alternate" type="application/rss+xml" title="CUNY Computational Vision and Convergence Laboratory &raquo; Comments Feed" href="../comments/feed/index.html" />
<script type="text/javascript">
/* <![CDATA[ */
window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/14.0.0\/svg\/","svgExt":".svg","source":{"concatemoji":"http:\/\/ccvcl.org\/wp-includes\/js\/wp-emoji-release.min.js?ver=6.4.2"}};
/*! This file is auto-generated */
!function(i,n){var o,s,e;function c(e){try{var t={supportTests:e,timestamp:(new Date).valueOf()};sessionStorage.setItem(o,JSON.stringify(t))}catch(e){}}function p(e,t,n){e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(t,0,0);var t=new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data),r=(e.clearRect(0,0,e.canvas.width,e.canvas.height),e.fillText(n,0,0),new Uint32Array(e.getImageData(0,0,e.canvas.width,e.canvas.height).data));return t.every(function(e,t){return e===r[t]})}function u(e,t,n){switch(t){case"flag":return n(e,"\ud83c\udff3\ufe0f\u200d\u26a7\ufe0f","\ud83c\udff3\ufe0f\u200b\u26a7\ufe0f")?!1:!n(e,"\ud83c\uddfa\ud83c\uddf3","\ud83c\uddfa\u200b\ud83c\uddf3")&&!n(e,"\ud83c\udff4\udb40\udc67\udb40\udc62\udb40\udc65\udb40\udc6e\udb40\udc67\udb40\udc7f","\ud83c\udff4\u200b\udb40\udc67\u200b\udb40\udc62\u200b\udb40\udc65\u200b\udb40\udc6e\u200b\udb40\udc67\u200b\udb40\udc7f");case"emoji":return!n(e,"\ud83e\udef1\ud83c\udffb\u200d\ud83e\udef2\ud83c\udfff","\ud83e\udef1\ud83c\udffb\u200b\ud83e\udef2\ud83c\udfff")}return!1}function f(e,t,n){var r="undefined"!=typeof WorkerGlobalScope&&self instanceof WorkerGlobalScope?new OffscreenCanvas(300,150):i.createElement("canvas"),a=r.getContext("2d",{willReadFrequently:!0}),o=(a.textBaseline="top",a.font="600 32px Arial",{});return e.forEach(function(e){o[e]=t(a,e,n)}),o}function t(e){var t=i.createElement("script");t.src=e,t.defer=!0,i.head.appendChild(t)}"undefined"!=typeof Promise&&(o="wpEmojiSettingsSupports",s=["flag","emoji"],n.supports={everything:!0,everythingExceptFlag:!0},e=new Promise(function(e){i.addEventListener("DOMContentLoaded",e,{once:!0})}),new Promise(function(t){var n=function(){try{var e=JSON.parse(sessionStorage.getItem(o));if("object"==typeof e&&"number"==typeof e.timestamp&&(new Date).valueOf()<e.timestamp+604800&&"object"==typeof e.supportTests)return e.supportTests}catch(e){}return null}();if(!n){if("undefined"!=typeof Worker&&"undefined"!=typeof OffscreenCanvas&&"undefined"!=typeof URL&&URL.createObjectURL&&"undefined"!=typeof Blob)try{var e="postMessage("+f.toString()+"("+[JSON.stringify(s),u.toString(),p.toString()].join(",")+"));",r=new Blob([e],{type:"text/javascript"}),a=new Worker(URL.createObjectURL(r),{name:"wpTestEmojiSupports"});return void(a.onmessage=function(e){c(n=e.data),a.terminate(),t(n)})}catch(e){}c(n=f(s,u,p))}t(n)}).then(function(e){for(var t in e)n.supports[t]=e[t],n.supports.everything=n.supports.everything&&n.supports[t],"flag"!==t&&(n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&n.supports[t]);n.supports.everythingExceptFlag=n.supports.everythingExceptFlag&&!n.supports.flag,n.DOMReady=!1,n.readyCallback=function(){n.DOMReady=!0}}).then(function(){return e}).then(function(){var e;n.supports.everything||(n.readyCallback(),(e=n.source||{}).concatemoji?t(e.concatemoji):e.wpemoji&&e.twemoji&&(t(e.twemoji),t(e.wpemoji)))}))}((window,document),window._wpemojiSettings);
/* ]]> */
</script>
<style id='wp-emoji-styles-inline-css' type='text/css'>

	img.wp-smiley, img.emoji {
		display: inline !important;
		border: none !important;
		box-shadow: none !important;
		height: 1em !important;
		width: 1em !important;
		margin: 0 0.07em !important;
		vertical-align: -0.1em !important;
		background: none !important;
		padding: 0 !important;
	}
</style>
<link rel='stylesheet' id='wp-block-library-css' href='../wp-includes/css/dist/block-library/style.min1e39.css?ver=6.4.2' type='text/css' media='all' />
<style id='classic-theme-styles-inline-css' type='text/css'>
/*! This file is auto-generated */
.wp-block-button__link{color:#fff;background-color:#32373c;border-radius:9999px;box-shadow:none;text-decoration:none;padding:calc(.667em + 2px) calc(1.333em + 2px);font-size:1.125em}.wp-block-file__button{background:#32373c;color:#fff;text-decoration:none}
</style>
<style id='global-styles-inline-css' type='text/css'>
body{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}:where(.is-layout-grid){gap: 0.5em;}body .is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}body .is-layout-flex{flex-wrap: wrap;align-items: center;}body .is-layout-flex > *{margin: 0;}body .is-layout-grid{display: grid;}body .is-layout-grid > *{margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}
.wp-block-navigation a:where(:not(.wp-element-button)){color: inherit;}
:where(.wp-block-post-template.is-layout-flex){gap: 1.25em;}:where(.wp-block-post-template.is-layout-grid){gap: 1.25em;}
:where(.wp-block-columns.is-layout-flex){gap: 2em;}:where(.wp-block-columns.is-layout-grid){gap: 2em;}
.wp-block-pullquote{font-size: 1.5em;line-height: 1.6;}
</style>
<link rel='stylesheet' id='bradbury-style-css' href='../wp-content/themes/bradbury-custom/style6b25.css?ver=2.1.4' type='text/css' media='all' />
<link rel='stylesheet' id='academia-icomoon-css' href='../wp-content/themes/bradbury-custom/css/icomoon6b25.css?ver=2.1.4' type='text/css' media='all' />
<script type="text/javascript" src="../wp-includes/js/jquery/jquery.minf43b.js?ver=3.7.1" id="jquery-core-js"></script>
<script type="text/javascript" src="../wp-includes/js/jquery/jquery-migrate.min5589.js?ver=3.4.1" id="jquery-migrate-js"></script>
<script type="text/javascript" src="../wp-content/themes/bradbury-custom/js/superfish.min68b3.js?ver=1" id="jquery-superfish-js"></script>
<script type="text/javascript" src="../wp-content/themes/bradbury-custom/js/jquery.flexslider-min68b3.js?ver=1" id="jquery-flexslider-js"></script>
<link rel="https://api.w.org/" href="../wp-json/index.html" /><link rel="alternate" type="application/json" href="../wp-json/wp/v2/pages/102.json" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="../xmlrpc0db0.php?rsd" />
<meta name="generator" content="WordPress 6.4.2" />
<link rel="canonical" href="index.html" />
<link rel='shortlink' href='../indexc5eb.html?p=102' />
<link rel="alternate" type="application/json+oembed" href="../wp-json/oembed/1.0/embed51a7.json?url=http%3A%2F%2Fccvcl.org%2Fpublications%2F" />
<link rel="alternate" type="text/xml+oembed" href="../wp-json/oembed/1.0/embeded43?url=http%3A%2F%2Fccvcl.org%2Fpublications%2F&amp;format=xml" />
<link rel="icon" href="../wp-content/uploads/2018/11/cropped-ccvcl_logo-32x32.png" sizes="32x32" />
<link rel="icon" href="../wp-content/uploads/2018/11/cropped-ccvcl_logo-192x192.png" sizes="192x192" />
<link rel="apple-touch-icon" href="../wp-content/uploads/2018/11/cropped-ccvcl_logo-180x180.png" />
<meta name="msapplication-TileImage" content="http://ccvcl.org/wp-content/uploads/2018/11/cropped-ccvcl_logo-270x270.png" />
</head>

<body class="page-template-default page page-id-102 custom-background wp-custom-logo wp-embed-responsive page-sidebar-left site-page-noslideshow">


<div id="container">

	<a class="skip-link screen-reader-text" href="#site-main">Skip to content</a>
	<div class="site-wrapper-all site-wrapper-boxed">

		
		<header id="site-masthead" class="site-section site-section-masthead">
			<div class="site-section-wrapper site-section-wrapper-masthead">
				<div id="site-logo"><a href="../index.html" class="custom-logo-link" rel="home"><img width="3000" height="3000" src="../wp-content/uploads/2018/11/ccvcl_logo.png" class="custom-logo" alt="Logo for CUNY Computational Vision and Convergence Laboratory" decoding="async" fetchpriority="high" /></a>			</div><!-- #site-logo --><!-- ws fix 
			--><div id="site-section-primary-menu">
									</div><!-- #site-section-primary-menu -->
			</div><!-- .site-section-wrapper .site-section-wrapper-masthead -->
		</header><!-- #site-masthead .site-section-masthead -->
		
<main id="site-main">

	
	<div class="site-page-content">
		<div class="site-section-wrapper site-section-wrapper-main clearfix">

			<div class="site-column site-column-content"><div class="site-column-wrapper clearfix"><!-- .site-column .site-column-1 .site-column-aside --><h1 class="page-title">Publications</h1><div class="entry-content">
<h2 class="wp-block-heading">2024</h2>



<p>Bilal AbdulRahman and Zhigang Zhu. <a href="../wp-content/uploads/2024/09/VISIGRAPP-2023-best-papers-Absolute-ROMP.pdf">Absolute-ROMP: Recovering Multi-person 3D Poses and Shapes with Absolute Scales from a Single RGB Image</a>. A. A. de Sousa et al. (Eds.), <em>Computer Vision, Imaging and Computer Graphics Theory and Applications, Part of the Book Series: Communications in Computer and Information Science ((CCIS,volume 2103)), Revised Selected Papers from the 18th International Joint Conference on Computer Vision, Imaging and Computer Graphics, VISIGRAPP 2023</em>, Lisbon, Portugal, February 19–21, 2023, pp. 73–97, First Online:&nbsp;22 August 2024. [<a href="http://bilal abdulrahman and zhigang zhu. absolute-romp: recovering multi-person 3d poses and shapes with absolute scales from a single rgb image. a. a. de sousa et al. (eds.), computer vision, imaging and computer graphics theory and applications, part of the book series:xn-- communications in computer and information science ((ccis,volume 2103)), revised selected papers from the 18th international joint conference on computer vision, imaging and computer graphics, visigrapp 2023, lisbon, portugal, february 1921, 2023, pp-p867n.xn-- 7397, first online-775k: 22 august 2024. https://doi.org/10.1007/978-3-031-66743-5_4">doi</a>]</p>



<p>Chen H, Zhu Z, Tang H, Blasch E, Pham KD, Chen G. <a href="../wp-content/uploads/2024/04/information-2912491.pdf">Flying Projectile Attitude Determination from Ground-Based Monocular Imagery with a Priori Knowledge</a>. <em>Information</em>. 2024; 15(4):201. <a href="https://doi.org/10.3390/info15040201">https://doi.org/10.3390/info15040201</a>.</p>



<p>Chen G. Q., Kashyap N., Zhang Z., Kucheva Y., Bobker M., Zhu Z. <a href="../wp-content/uploads/2024/02/MMBEE_Multimedia_Smart_Conference-Final.pdf">Creating and Analyzing a Multimedia Dataset for Building Energy Efficiency Estimation</a>. <em>International Conference on SMART MULTIMEDIA</em>, March 27-29, 2024 (Full Paper).</p>



<p>Jiawei Liu, Wayne Lam, Zhigang Zhu, Hao Tang. <a href="../wp-content/uploads/2024/02/ICSM24_0046_FI.pdf">Surveying Sidewalk Materials for and by Individuals Who Are Blind or Have Low Vision: Audio Data Collection and Classification</a>. <em>International Conference on SMART MULTIMEDIA</em>, March 27-29, 2024 (Late Breaking Paper).</p>



<p>Xia J, Gong G, Liu J, Zhu Z, Tang H. Pedestrian-Accessible Infrastructure Inventory: Enabling and Assessing Zero-Shot Segmentation on Multi-Mode Geospatial Data for All Pedestrian Types. <em>Special Issue on Image and Video Processing for Blind and Visually Impaired</em>,<em> Journal of Imaging</em>. 21 February 2024; 10(3):52. [<a href="https://doi.org/10.3390/jimaging10030052">doi</a>] </p>



<p>Wang, X., Tang, H. and Zhu, Z. GMC: A General Framework of Multi-stage Context Learning and Utilization for Visual Detection Tasks. <em>Computer Vision and Image Understanding,</em> Accepted 21 January 2024, Available online 5 February 2024, 103944, ISSN 1077-3142 [<a href="https://doi.org/10.1016/j.cviu.2024.103944">doi</a>].</p>



<p>Xuan Wang, <a href="../wp-content/uploads/2024/09/CUNY-GC_PhD-Thesis_Xuan_Wang-2024.pdf">Context in Computer Vision: A Taxonomy, Multi-stage Integration, and a General Framework</a>, Ph.D. Thesis (Mentors: Prof. Zhigang Zhu, Prof. Hao Tang). The Graduate Center, CUNY. Defended on January 17th, 2024</p>



<h2 class="wp-block-heading">2023</h2>



<p>Zhu, Z.,&nbsp; Chen, J., Tang, H. and Ruci, A. <a href="../wp-content/uploads/2023/11/20231010-Ribbon-Copy-SYSTEM-AND-METHOD-FOR-REAL-TIME-INDOOR-NAVIGATION.pdf">SYSTEM AND METHOD FOR REAL-TIME INDOOR NAVIGATION</a>. <em>US Patent,</em> Application Serial No. 17/399,457; Filed on August 11, 2021; Approved on June 28, 2023; Issued on October 10, 2023 (Patent No 11785430).</p>



<p>Alan Tepoxtecatl, Crystal Yang, Max Sehaumpai, William H. Seiple and Zhigang Zhu. <a href="../wp-content/uploads/2023/11/MAC-You-Vision_URTC_manuscript_final_submit.pdf">MAC-You-Vision: A Progressive Training Application for Patients with Age-Related Macular Degeneration</a>.<em> &nbsp;IEEE MIT Undergraduate Research Technology Conference (URTC)</em>, October 6-8, 2023 at MIT, Cambridge USA (hybrid).</p>



<p>Jin Chen and Zhigang Zhu. <a href="https://rdcu.be/dh4Yg">Real-Time 3D Object Detection, Recognition and Presentation Using a Mobile Device for Assistive Navigation</a>. <em>Springer Nature Journal (Computer Science)</em>, 4:543, Published: 29 July 2023. [<a href="https://doi.org/10.1007/s42979-023-01881-3">doi</a>]</p>



<p>DiAndra Phillip, Jin Chen, Fani Maksakuli, Arber Ruci, E’edresha Sturdivant, and Zhigang Zhu. 2023. <a href="../wp-content/uploads/2023/06/eenergy23companion_1-4.pdf">Improving Building Energy Efficiency through Data Analysis</a>. In <em>The 14th ACM International Conference on Future Energy Systems (e-Energy ’23 Companion)</em>, June 20–23, 2023, Orlando, FL, USA. ACM, New York, NY, USA, 8 pages. [<a href="https://doi.org/10.1145/3599733.3600244">doi</a>] </p>



<p>Chen, J.; Ramnath, S.; Samaroo, T.; Maksakuli, F.; Ruci, A.; Sturdivant, E. and Zhu, Z.&nbsp;(2023).&nbsp;<a href="../wp-content/uploads/2023/06/IMPROVE_2023_26_CR-1.pdf">An Integrated Mobile Vision System for Enhancing the Interaction of Blind and Low Vision Users with Their Surroundings<strong>.</strong></a><strong>&nbsp;</strong>In&nbsp;<em>Proceedings of the 3rd International Conference on Image Processing and Vision Engineering</em>, April 21-23 , 2023 ISBN 978-989-758-642-2, ISSN 2795-4943, pages 180-187.&nbsp;&nbsp;[<a href="https://www.doi.org/10.5220/0011984400003497">DOI</a>] &nbsp;&nbsp;</p>



<p>Zhang, Zihao; Epstein, Susan L.; Breen, Casey; Xia, Sophia; Zhu, Zhigang; Volkmann, Christian. <a href="https://gispoint.de/gisopen-paper/7751-robots-in-the-garden-artificial-intelligence-and-adaptive-landscapes.html?IDjournalTitle=6&amp;cHash=a61907bf26c28fde2dfbb235c83035fe">Robots in the Garden: Artificial Intelligence and Adaptive Landscapes</a>.  <em>Journal of Digital Landscape Architecture</em>, 8-2023, pp. 264-272. © Wichmann Verlag, VDE VERLAG GMBH · Berlin · Offenbach. ISBN 978-3-87907-740-3, ISSN 2367-4253, e-ISSN 2511-624X, doi:10.14627/537740028 [<strong><em>The Journal of Digital Landscape Architecture award 2023 on SCIENTIFIC EXCELLENCE</em></strong>]</p>



<p>Xuan Wang, Jiawei Liu, Hao Tang, Zhigang Zhu, and William H. Seiple, <a href="https://scholarworks.csun.edu/handle/10211.3/225166"> An AI-enabled Annotation Platform for Storefront Accessibility and Localization,</a><em> Journal on Technology &amp; Persons with Disabilities. </em><a href="https://scholarworks.csun.edu/handle/10211.3/225159">Volume 11</a>, June 2023, Robles, A., (Eds): CSUN Assistive Technology Conference © 2023 California State University, Northridge, pp. 76-94.</p>



<p>Nicholas Karkut, Alexey Kiriluk, Zihao Zhang, Zhigang Zhu, <a href="../wp-content/uploads/2023/03/Vegetation-and-Amenity-Mapping-IMPROVE2023_Camera-Ready-8p.pdf">Vegetation Coverage and Urban Amenity Mapping Using Computer Vision and Machine Learning</a>. In <em>Proceedings of the 3rd International Conference on Image Processing and Vision Engineering (IMPROVE 2023)</em>, April 21-23 , 2023. ISBN 978-989-758-642-2; ISSN 2795-4943, SciTePress, pages 67-75. [<a href="https://www.doi.org/10.5220/0011705100003497">DOI</a>] </p>



<p>Bilal Abdulrahman &amp; Zhigang Zhu, <a href="../wp-content/uploads/2023/03/Absolute-ROMP-VISAPP-2023.pdf">Absolute-ROMP: Absolute Multi-person 3D Mesh Prediction from a Single Image</a>. <em>VISAPP 2023, the 18th International Conference on Computer Vision Theory and Applications</em>, Feb 19-21, 2023 (full oral paper). [<a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011629500003417">DOI</a>]</p>



<p>Xuan Wang, Hao Tang &amp; Zhigang Zhu, <a href="../wp-content/uploads/2023/03/Context-VISAPP2023-Final.pdf">A General Context Learning and Reasoning Framework for Object Detection in Urban Scenes</a>. <em>VISAPP 2023, the 18th International Conference on Computer Vision Theory and Applications,</em> Feb 19-21, 2023 full oral paper). [<a href="https://www.scitepress.org/Link.aspx?doi=10.5220/0011637600003417">DOI</a>]</p>



<p>Qi, Jianing, Hao Tang, and Zhigang Zhu.  &#8220;Exploring an Affective and Responsive Virtual Environment to Improve Remote Learning&#8221;, <em>Virtual Worlds</em> 2, no. 1, 2023: 53-74. [<a href="https://doi.org/10.3390/virtualworlds2010004">doi</a>] </p>



<p>Xuan Wang and Zhigang Zhu. Context Understanding in Computer Vision: A Survey. <em>Computer Vision and Image Understanding</em>, Elsevier, Xuan Wang and Zhigang Zhu. Context Understanding in Computer Vision: A Survey. <em>Computer Vision and Image Understanding</em>, Elsevier, Volume 229, March 2023, 103646. Available <a href="https://doi.org/10.1016/j.cviu.2023.103646">online</a> February 7, 2023. [<a href="https://doi.org/10.1016/j.cviu.2023.103646">doi</a>] [<a href="https://arxiv.org/abs/2302.05011">preprint on arXiv</a>]</p>



<h2 class="wp-block-heading">2022</h2>



<p>Bilal Abdulrahman &amp; Zhigang Zhu, Real-time pedestrian pose estimation, tracking and localization for social distancing, <em>Machine Vision and Applications</em>, 34(8). Published: 05 December 2022 (<a href="https://link.springer.com/article/10.1007/s00138-022-01356-0">DOI</a>)</p>



<p>X. Wang, J. Chen, H. Tang and Z. Zhu. <a href="https://dl.acm.org/doi/pdf/10.1145/3512527.3531361">MultiCLU: Multi-stage Context Learning and Utilization for Storefront Accessibility Detection and Evaluation</a>. <em>ACM International Conference on Multimedia Retrieval</em>, Newark, NJ, USA, June 27-30, 2022. Pages 304–312. [<a href="http://doi.acm.org/?doi=3512527.3531361">doi</a> with supplemental video] <em><u>(accepted as a full paper).</u></em></p>



<p>Jiawei Liu, Hao Tang, William Seiple, Zhigang Zhu. <a href="https://scholarworks.csun.edu/handle/10211.3/223472">Annotating Storefront Accessibility Data Using Crowdsourcing</a>. <em>Journal on Technology &amp; Persons with Disabilities.</em> Volume 10, June 2022, pp 154-170.</p>



<p>J. Chen, A. Ruci, E. Sturdivant, Z. Zhu. <a href="../wp-content/uploads/2022/06/ARSO2022-AssistiveIndoorNavigation-CameraReady-Rev.pdf">ARMSAINTS: An AR-based Real-time Mobile System for Assistive Indoor Navigation with Target Segmentation</a>. <em>IEEE International Conference on Advanced Robotics and Its Social Impacts (ARSO)</em>, May 28-30, 2022, Long Beach, CA, USA</p>



<p>Chen, J. and Zhu, Z.(2022). <a href="../wp-content/uploads/2022/04/IMPROVE_2022_15_CR.pdf">Real-Time 3D Object Detection and Recognition using a Smartphone</a>. In <em><em>Proceedings of the 2nd International Conference on Image Processing and Vision Engineering (IMPROVE 2022)</em>, </em>April 22-24, ISBN 978-989-758-563-0, ISSN 2795-4943, pages 158-165.</p>



<p>J. Chen, T. Ro and Z. Zhu, &#8220;Emotion Recognition With Audio, Video, EEG, and EMG: A Dataset and Baseline Approaches,&#8221; in <em>IEEE Access</em>, vol. 10, pp. 13229-13242, 2022, <a href="https://doi.org/10.1109/ACCESS.2022.3146729">doi: 10.1109/ACCESS.2022.3146729</a>. (The PME4 Dataset can be accessed and downloaded for research purposes <a href="https://doi.org/10.6084/m9.figshare.18737924">here</a>&nbsp;, and the code is available <a rel="noreferrer noopener" target="_blank" href="https://github.com/jinchen1036/PME4-Emotion-Recognition">here</a>.)</p>



<p>X. Li, L. Zhang and Z. Zhu, SnapshotNet: Self-supervised Feature Learning for Point Cloud Data Segmentation Using Minimal Labeled Data. <em>Computer Vision and Image Understanding</em>. Vol. 216, February 2022 (<a href="https://doi.org/10.1016/j.cviu.2021.103339">Available online </a>21 December 2021) [Click <a href="https://urldefense.proofpoint.com/v2/url?u=https-3A__authors.elsevier.com_c_1eOUX3qy-2D3T4mC&amp;d=DwMFaQ&amp;c=4NmamNZG3KTnUCoC6InoLJ6KV1tbVKrkZXHRwtIMGmo&amp;r=KQbVpoJK3r1M9kJrt4YwwzaPui7fLvZ_tDOejpdiKf8&amp;m=N3DC1sKzeRHUAaakMZsZ7ZYfxB4hbKhTaq1Tw2Wn6Es&amp;s=PZsteblCYM3swRtMHWNK5XHZcqHuWEFH2SJ7KHi0qFo&amp;e=">here</a> for a free download before 03/01/2022] <a href="https://doi.org/10.1016/j.cviu.2021.103339">[doi]</a> [<a href="https://ars.els-cdn.com/content/image/1-s2.0-S1077314221001740-mmc1.mp4">video presentation</a>] [<a href="http://arxiv.org/abs/2201.04833">preprint on arXiv</a>]</p>



<h2 class="wp-block-heading">2021</h2>



<p>Jie Wei, Zhigang Zhu, Erik Blasch, Bilal Abdulrahman, Billy Davila, Shuoxin Liu, Jed Magracia, Ling Fang, <a href="https://arxiv.org/abs/2110.14518">NIDA-CLIFGAN: Natural Infrastructure Damage Assessment through Efficient Classification Combining Contrastive Learning, Information Fusion and Generative Adversarial Networks</a>. <em> Artificial Intelligence for Humanitarian Assistance and Disaster Response Workshop</em> (<em>AI + HADR 2021</em>), December 13, 2021 @ NeurIPS 2021 (Virtual).</p>



<p>G. Olmschenk, X. Wang, H. Tang, and Z. Zhu. Impact of Labeling Schemes on Dense Crowd Counting Using Convolutional Neural Networks with Multiscale Upsampling. <em>International Journal of Pattern Recognition and Artificial Intelligence, </em>Vol. 35, No. 13, September 15, 2021 (<a href="https://doi.org/10.1142/S0218001421600120">DOI with free downloadable PDF</a>)</p>



<p>H. N. Ou, S, H. Ro, J. Gong, and Z. Zhu. <a href="../wp-content/uploads/2021/08/IST-2021-ADI-Final.pdf">Building an Annotated Damage Image Database to Support AI-Assisted Hurricane Impact Analysis</a>. <em>The 2021 IEEE International Conference on Imaging Systems and Techniques</em>, Aug 24-26, 2021</p>



<p>S. Alsheimer and Z. Zhu. <a href="../wp-content/uploads/2021/08/IST_2021_Submission_HLSM_Final.pdf">Monocularly Generated 3D High Level Semantic Model by Integrating Deep Learning Models and Traditional Vision Techniques</a>. <em>The 2021 IEEE International Conference on Imaging Systems and Techniques</em>, Aug 24-26, 2021</p>



<p>Y. Wu, H. Vo, J. Gong, and Z. Zhu. <a href="../wp-content/uploads/2021/07/egpgv_2021_unitypic_camera_ready_v2_compressed.pdf">UnityPIC: Unity Point-Cloud Interactive Core</a>. <em>2021 Eurographics Symposium on Parallel Graphics and Visualization</em>, M. Hadwiger, M. Larsen, F. Sadlo (Editors), Eurographics Proceedings © 2021 The Eurographics Association (<a href="https://diglib.eg.org/handle/10.2312/pgv20211044">link</a>).</p>



<p>M. Xia, N. Chen, Y. Tang, Z. Zhu. ParaShop: Shopping Assistance to ASD Individuals with a Mobile AR App. J<em>ournal on Technology and Persons with Disabilities</em>. <em>Volume 9</em> (<a href="https://scholarworks.csun.edu/handle/10211.3/219932">Download</a>), May 2021. pp 1-17.ISSN: 2330-4216</p>



<p>J. Chen, Y. T. Yang, X. Zhu, Z. Zhu. Share&amp;Care: A Family Interaction Application for Older Adults Living Alone. <em>Journal on Technology and Persons with Disabilities</em>. Volume 9 (<a href="https://scholarworks.csun.edu/handle/10211.3/219933">Download</a>), May 2021. pp 18-34. ISSN: 2330-4216</p>



<p>Z. Zhu, G. Blumenkrantz, K. Olives, <a href="../wp-content/uploads/2021/03/CCNY-BEAT-for-ISEC-2021-Camera-Ready.pdf">BEAT: Branding and Entrepreneurship of Assistive Technology for Social Good</a>. <em>The 11th Integrated STEM Education Conference (ISEC)</em>, March 13, 2021.</p>



<p>X. Li and Z. Zhu, <a href="../wp-content/uploads/2020/12/VISAPP21__Snapshot_based_self_supervised_learning.pdf">A Snapshot-based Approach for Self-supervised Feature Learning and Weakly-supervised Classification on Point Cloud Data</a>. <em>VISAPP 2021, the 16th International Conference on Computer Vision Theory and Applications</em>, Feb 8-10, 2021</p>



<p>Zhigang Zhu, Vishnu Nair, Greg Olmschenk and Bill Seiple. <a href="../wp-content/uploads/2020/12/ASSIST-AI4SG-IJCAI-2021-camera-ready.pdf">ASSIST: Assistive Sensor Solutions for Independent and Safe Travel of Blind and Visually Impaired People</a>. <em>IJCAI <a href="https://crcs.seas.harvard.edu/event/ai-social-good-workshop-0">Workshop on AI for Social Good (AI4SG)</a></em>, January 08, 2021 (long oral talk) &amp; (<a href="../wp-content/uploads/2021/01/SAT-Hub-and-ASSIST-Zhu-AI4SG-2021-Poster.pdf">poster</a>).</p>



<h2 class="wp-block-heading">2020</h2>



<p>Z. Zhu, J. Chen, L. Zhang, Y. Chang, T. Franklin, H. Tang and A. Ruci. <a href="https://www.igi-global.com/article/iassist/267766">iASSIST: An iPhone-Based Multimedia Information System for Indoor Assistive Navigation</a>. <em>International Journal of Multimedia Data Engineering and Management (IJMDEM)</em>. Volume 11, Issue 4, November 2020 (<a href="https://par.nsf.gov/servlets/purl/10211624">pdf</a>)</p>



<p>Bilal Abdulrahman and Zhigang Zhu, <a href="../wp-content/uploads/2020/11/Social-Distancing-AAAI_AI4SG-2020.pdf">Measuring and Visualizing Social Distancing Using Deep Learning and 3D Computer Vision</a>. AI for Social Good &#8211; AAAI Fall Symposium 2020, November 13 – 14, 2020 (<a href="https://youtu.be/Lf4d5cKZBBs">YouTube Video Presentation</a>)</p>



<p>Zhang, L., Wu, K., Yang, B., Tang, H., and Zhu, Z. <a href="../wp-content/uploads/2020/09/1433-camera-ready-final.pdf">Exploring Virtual Environments by Visually Impaired Using a Mixed Reality Cane Without Visual Feedback</a>, ISMAR 2020 &#8211; International Symposium on Mixed and Augmented Reality, November 9-13, 2020.</p>



<p>Mengting Xia, Nan Chen, Yuemin Tang, Zhigang Zhu. <a href="../wp-content/uploads/2020/12/ParaShop_MIT_Final_v-accepted.pdf">ParaShop: A Mobile AR App in Assisting People with ASD in Shopping</a>. <em>2020 IEEE MIT Undergraduate Research Technology Conference (URTC)</em>, October 9-11, 2020 at MIT, Cambridge USA (virtually).</p>



<p>Jin Chen, Yu Ting Yang, Xiaohong Zhu, Zhigang Zhu. <a href="../wp-content/uploads/2020/12/ShareCare_MIT_URTC_Camera_Ready.pdf">Share&amp;Care: A Senior-Friendly Family Interaction Application</a>. <em>2020 IEEE MIT Undergraduate Research Technology Conference (URTC)</em>, October 9-11, 2020 at MIT, Cambridge USA (virtually).</p>



<p>V. Nair, G. Olmschenk, W. H. Seiple, Z. Zhu. ASSIST: Evaluating the Usability and Performance of an Indoor Navigation Assistant for Blind and Visually Impaired People (<a href="../wp-content/uploads/2020/09/ASSIST-JAT-Paper-Accepted-Manuscript-2020.pdf">Accepted Manuscript</a>). <em>Assistive Technology, The Official Journal of RESNA. </em><a href="https://doi.org/10.1080/10400435.2020.1809553">Published Online</a> September 02, 2020 (<a href="https://www.tandfonline.com/eprint/ICWH7DVQRTVRTUXJ58I4/full?target=10.1080/10400435.2020.1809553">e-print</a>, free for the first 50 copies; <a href="https://youtu.be/Hq1EYS9Jncg">YouTube demo of ASSIST</a>)</p>



<p>Y. Chang, J. Chen, T. Franklin, L. Zhang, A. Ruci, H. Tang and Z. Zhu. <a href="../wp-content/uploads/2020/07/iASSIST_IEEE_IRI_2020_No-8-Cemera-Ready.pdf">Multimodal Information Integration for Indoor Navigation Using a Smartphone</a>. <em>IRI2020 -The 21st IEEE International Conference on Information Reuse and Integration for Data Science</em>, August 11-13, 2020 (<strong><em>Full Regular Paper for Oral Presentation, 28% acceptance rate</em></strong>). (<a href="https://youtu.be/iH1LZ-HAjWs">YouTube demo of iASSIST</a>).</p>



<p>Z. Zhu, J. Gong, C. Feeley, H. Vo, H. Tang, A. Ruci, B. Seiple and Z. Y. Wu. <a href="../wp-content/uploads/2020/07/sat-hub-ai-for-social-good-2020.pdf">SAT-Hub: Smart and Accessible Transportation Hub for Assistive Navigation and Facility Management</a>. <em><a href="https://aiforgood2020.github.io/">Harvard CRCS Workshop on AI for Social Good</a>, </em>July 20-21, 2020 (<a href="../wp-content/uploads/2020/07/SAT-Hub-Zhu-AI4SG-2000-Poster.png">poster</a>)</p>



<p>Zhu Z. (2020) <a href="../wp-content/uploads/2020/07/Zhu2020_ReferenceWorkEntry_VideoMosaicing.pdf">Video Mosaicing</a>. In: Ikeuchi K. (eds) Computer Vision. Springer, Cham. (<a href="https://doi.org/10.1007/978-3-030-03243-2_68-1">doi</a>)</p>



<p>Zhu Z. (2020) <a href="../wp-content/uploads/2020/04/Zhu2020_ReferenceWorkEntry_VideoMosaicing.pdf">Video Mosaicing</a>. In: Ang M., Khatib O., Siciliano B. (eds) <em>Encyclopedia of Robotics. Springer</em>, Berlin, Heidelberg. First Online, 30 March 2020 (<a href="https://doi.org/10.1007/978-3-642-41610-1_106-1">doi</a>)</p>



<p>G. Olmschenk, H. Tang, and Z. Zhu. <a href="../wp-content/uploads/2020/04/2020_ikNN_VISAPP-Camera-Ready.pdf">Improving Dense Crowd Counting Convolutional Neural Networks using Inverse k-Nearest Neighbor Maps and Multiscale Upsampling</a>.  <em>VISAPP 2020, the 15th International Conference on Computer Vision Theory and Applications</em>. [<a href="https://arxiv.org/abs/1902.05379">arXiv</a>]</p>



<p>Tang, H., Wang, X., Olmschenk, G. Feeley, C., Zhu, Z. Assistive Navigation and Interaction with Mobile &amp; VR Apps for People with ASD. <em>The 35th CSUN Assistive Technology Conference</em>, March 9-13, 2020.</p>



<h2 class="wp-block-heading">2019</h2>



<p>J. Venerella, L. Sherpa, T. Franklin, H. Tang and Z. Zhu. <a href="../wp-content/uploads/2020/04/1051-camera.pdf">Integrating AR and VR for Mobile Remote Collaboration</a>. <em>The 18th IEEE Int. Symposium on Mixed and Augmented Reality(ISMAR 2019)</em>, Beijing (China), on October 14-18, 2019</p>



<p>L. Chen, Y. Zou, Y. Chang, J. Liu, B. Lin and Z. Zhu, <a href="../wp-content/uploads/2020/04/Paper-ID-1082-to-ISMAR-2019-Poster-Final-version-to-be-uploaded-20190813.pdf">Multi-level scene modeling and matching for smartphone-based indoor localization</a>. <em>The 18th IEEE Int. Symposium on Mixed and Augmented Reality (ISMAR 2019)</em>, Beijing (China), on October 14-18, 2019</p>



<p>Greg Olmschenk, Zhigang Zhu, and Hao Tang. <a href="https://arxiv.org/abs/1811.11269">Generalizing semi-supervised generative adversarial networks to regression</a>. <em>Computer Vision and Image Understanding Journal &#8211; Special Issue on Adversarial Learning in Computer Vision</em>. vol 186,  Elsevier, September 2019 (<a href="https://doi.org/10.1016/j.cviu.2019.06.004">doi</a>).</p>



<p>L. Zhang and Z. Zhu, <a href="../wp-content/uploads/2020/04/ContrastNet_3DV_CR.pdf">Unsupervised Feature Learning for Point Cloud Understanding by Contrasting and Clustering Using Graph Convolutional Neural Networks</a>, <em>International Conference on 3D Vision (3DV)</em>, September 16-19, 2019 (<a href="../wp-content/uploads/2020/04/ContrastNet_3DV_poster.pdf">poster</a>)</p>



<p>Greg Olmschenk. <a href="../olmschenk-dissertation/index.html"><em>Semi-supervised Regression with Generative Adversarial Networks Using Minimal Labeled Data &#8211; Critical Issues, Network Behaviors, and Applications</em></a><em>.</em> Doctoral Dissertation (Advisors: Professor Zhigang Zhu, Professor Hao Tang). Computer Science. The Graduate Center of the City University of New York. August 2019.</p>



<p>Greg Olmschenk, Jin Chen, Hao Tang, Zhigang Zhu. <a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Weakly Supervised Learning for Real-World Computer Vision Applications/Olmschenk_Dense_Crowd_Counting_Convolutional_Neural_Networks_with_Minimal_Data_using_CVPRW_2019_paper.pdf">Dense </a><a href="../wp-content/uploads/2019/08/2019_CVPR_LID_workshop_DG_GAN.pdf">Crowd</a><a href="http://openaccess.thecvf.com/content_CVPRW_2019/papers/Weakly Supervised Learning for Real-World Computer Vision Applications/Olmschenk_Dense_Crowd_Counting_Convolutional_Neural_Networks_with_Minimal_Data_using_CVPRW_2019_paper.pdf"> Counting Convolutional Neural Networks with Minimal Data using Semi-Supervised Dual-Goal Generative Adversarial Networks</a>. <em>IEEE Conference on Computer Vision and Pattern Recognition: Learning with Imperfect Data Workshop</em>. June 2019.</p>



<p>L. Zhang and Z. Zhu. <a href="../wp-content/uploads/2020/04/ContrastNet_CVPRW.pdf">Unsupervised Feature Learning for Point Cloud by Contrasting and Clustering with Graph Convolutional Neural Network</a>, <em>CVPR Workshop on 3D Scene Understanding for Vision, Graphics, and Robotics</em>, June 16-20, 2019</p>



<p>
Jie Wei, Chi-Him Liu, Zhigang Zhu, Lindsay R.
Cain, Vincent J. Velten. Vehicle Engine Classification Using Normalized
Tone-Pitch Indexing and Neural Computing on Short Remote Vibration Sensing
Data. <em>Expert Systems With Applications (ESWA)</em>,
Elsevier, Vol 115, Jan 2019, pp 276-286 (<a href="https://doi.org/10.1016/j.eswa.2018.07.073">doi</a>)</p>



<h2 class="wp-block-heading">2018</h2>



<p> Vishnu Nair, Manjekar Budhai, Greg Olmschenk, William H. Seiple, Zhigang Zhu, <a href="https://openaccess.thecvf.com/content_ECCVW_2018/papers/11134/Nair_ASSIST_Personalized_indoor_navigation_via_multimodal_sensors_and_high-level_semantic_ECCVW_2018_paper.pdf">Personalized indoor navigation via multimodal sensors and high-level semantic information</a>, <em>Sixth International Workshop on Assistive Computer Vision and Robotics (ACVR)</em>. Munich, Germany, 9th September 2018 (Oral and Poster Presentation) (<a href="https://link.springer.com/chapter/10.1007%2F978-3-030-11024-6_9">Book Link</a>)</p>



<p>F. Hu, H. Tang, A. Tsema, and Z. Zhu,&nbsp;<a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=vpY-DwAAQBAJ&amp;oi=fnd&amp;pg=PA1&amp;ots=E3frk-V-yQ&amp;sig=BG2u8JI7xL0piZ7JHAqRhThdVFw#v=onepage&amp;q&amp;f=false">Computer Vision for Sight: Computer Vision Techniques to Assist Visually Impaired People to Navigate in an Indoor Environment</a>&nbsp;<em>, COMPUTER VISION FOR ASSISTIVE HEALTHCARE,</em>&nbsp;Giovanni Maria Farinella and Marco Leo , Computer Vision and Pattern Recognition Series, Elsevier, May, 2018 , pp 1-49 , (<a href="https://www.sciencedirect.com/science/book/9780128134450">Book Link</a>)</p>



<p>F. Abtahi, T. Ro, W. Li, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Abtahi_WACV18_ID367_Camera_Ready.pdf">Emotion Analysis Using Audio/Video, EMG and EEG: A Dataset and Comparison Study</a><em>, IEEE Winter Conference on Application of Computer Vision (WACV),</em>&nbsp;Lake Tahoe, NV/CA, March 12-14, 2018 , pp 10-19</p>



<p>G. Olmschenk, H. Tang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/crowd_gans_wacv_paper_final.pdf">Crowd Counting With Minimal Data Using Generative Adversarial Networks For Multiple Target Regression</a><em>, IEEE Winter Conference on Application of Computer Vision (WACV),</em>&nbsp;Lake Tahoe, NV/CA, March 12-14, 2018 , pp 1151-1159</p>



<p>J. Settineri, F. Shahollari, A. Samdaria, C. Cavalluzzi, and Z. Zhu,&nbsp;VR for ASD: Therapeutic Environments for Individuals on the Autism Spectrum&nbsp;<em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;6, CSUN Center on Disabilities, March, 2018 , pp 1-17 , (<a href="http://scholarworks.csun.edu/handle/10211.3/202982">Download</a>&nbsp;)</p>



<p>C. Colena, N. Kashyap, D. Yau, C. Cavalluzzi, and Z. Zhu,&nbsp;Panoramik: Finding and Locating Objects via Panoramic Camera Techniques&nbsp;<em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;6, CSUN Center on Disabilities, March, 2018 , pp 18-31 , (<a href="http://scholarworks.csun.edu/handle/10211.3/202983">Download</a>&nbsp;)</p>



<p>V. Nair, C. Tsangouri, B. Xiao, G. Olmschenk, W. Seiple, and Z. Zhu,&nbsp;A Hybrid Indoor Positioning System for Blind and Visually Impaired Using Bluetooth and Google Tango&nbsp;<em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;6, CSUN Center on Disabilities, March, 2018 , pp 61-81 , (<a href="http://scholarworks.csun.edu/handle/10211.3/202986">Download</a>&nbsp;)</p>



<p>M. Goldberg, Z. Zhu, and Z. Zhang,&nbsp;How do We Aid Visually Impaired People Safely Manage Unfamiliar Environments?&nbsp;<em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;6, CSUN Center on Disabilities, March, 2018 , pp 261-272 , (<a href="http://scholarworks.csun.edu/handle/10211.3/203000">Download</a>&nbsp;)</p>



<p>W. Li, C. Tsangouri, F. Abtahi, and Z. Zhu,&nbsp;A Recursive Framework for Expression Recognition: From Web Images to Deep Models to Game Dataset.&nbsp;<em>, Machine Vision and Applications,</em>&nbsp;https://doi.org/10.1007/s00138-017-0904-9, Springer-Verlag GmbH Germany, First Online: 12 February, 2018 , (<a href="http://rdcu.be/GPpE">SpringerNature</a>&nbsp;)</p>



<p>W. Li, F. Abtahi, Z. Zhu, and L. Yin,&nbsp;<a href="https://ieeexplore.ieee.org/ielaam/34/8478843/8253509-aam.pdf">EAC-Net: Deep Nets with Enhancing and Cropping for Facial Action Unit Detection</a>&nbsp;<em>, IEEE Transactions on Pattern Analysis and Machine Intelligence,</em>&nbsp;Volume PP, Issue 99, IEEE, 10 January 2018, 2018 , (<a href="http://dx.doi.org/10.1109/TPAMI.2018.2791608">DOI</a>&nbsp;)</p>



<h2 class="wp-block-heading">2017</h2>



<p>F. Hu, Z. Zhu, J. Mejia, H. Tang, and J. Zhang,&nbsp;<a href="../wp-content/uploads/2019/01/ElectronEng-01-00074.pdf">Real-time indoor assistive localization with mobile omnidirectional vision and cloud GPU acceleration</a><em>, AIMS Electronics and Electronic Engineering,</em>&nbsp;1(1), AIMS Press, December 13, 2017 , 74-99 , (<a href="http://www.aimspress.com/article/10.3934/ElectrEng.2017.1.74">link</a>&nbsp;)</p>



<p>J. Gong, C. Feeley, H. Tang, G. Olmschenk, V. Nair, Z. Zhou, Y. Yu, K. Yamamoto, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Gong-Zhu-ICSI-2017.pdf">Building Smart and Accessible Transportation Hubs with Internet of Things, Big Data Analytics, and Affective Computing</a><em>, ASCE 2017 International Conference of Sustainable Infrastructure,</em>&nbsp;October 22-25, 2017 , 126-138</p>



<p>Z. Zhu, ,&nbsp;<a href="../wp-content/uploads/2019/01/Assistive-Vision-Final-2017.pdf">Human-Machine Perception and Assistive Technology (in Chinese)</a><em>, Overseas Scholars,</em>&nbsp;Special Issue on Information Technology, Chinese Association for Science and Technology, USA (CAST-USA), ISSN: 1556-861X, 2017 , 67-81 , (<a href="http://www-cs.engr.ccny.cuny.edu/~zhu/MAP4VIP/Zhu-EFRI-Poems-2017.pdf">Slides with the original 16 poems in both Chinese and English</a>&nbsp;)</p>



<p>Q. Chen, M. Khan, C. Tsangouri, C. Yang, B. Li, J. Xiao, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/SmartCane-CYBER2017-final.pdf">CCNY Smart Cane</a><em>, IEEE-CYBER 2017-The 7th Annual IEEE Int. Conf. on CYBER Technology in Automation, Control, and Intelligent Systems,</em>&nbsp;Hawaii, USA, July 31 – August 4, 2017</p>



<p>E. Molina, W. Khoo, H. Tang, and Z. Zhu,&nbsp;Video Image Registration&nbsp;<em>, Theory and Applications of Image Registration,</em>&nbsp;Chapter 10, Arthur A Goshtasby, John Wiley &amp; Sons, Inc., 2017 , 357-396 , (<a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-1119171717.html">link</a>&nbsp;)</p>



<p>W. Li, F. Abtahi, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/cvpr_cam_ready_zhufinal.pdf">Action Unit Detection with Region Adaptation, Multi­labeling Learning and Optimal Temporal Fusing</a><em>, IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2017),</em>&nbsp;Honolulu, Hawaii, USA, July 21­-26, 2017</p>



<p>H. Tang, T. Amuneke, H. Zou, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Indoor_Map_Learning_for_the_Visually_Impaired.pdf">Indoor Map Learning for the Visually Impaired</a><em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;V5, 2017</p>



<p>W. Li, F. Abtahi, Z. Zhu, and L. Yin,&nbsp;<a href="../wp-content/uploads/2019/01/EAC_Net_ready.pdf">EAC-Net: A Region-based Deep Enhancing and Cropping Approach for Facial Action Unit Detection</a><em>, The 12th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2017),</em>&nbsp;Washington, DC, May 30 –June 3, 2017</p>



<p>G. Olmschenk, H. Tang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/CRV2017-Pitch_and_Roll_Camera_Orientation_From_a_Single_2D_Image_Using_Convolutional_Neural_Networks.pdf">Pitch and Roll Camera Orientation From a Single 2D Image Using Convolutional Neural Networks</a><em>, Proceedings of the 14th Conference on Computer and Robot Vision,</em>&nbsp;Edmonton, Alberta, May 17-19, 2017</p>



<p>Z. Zhu, and J. Xiao,&nbsp;<a href="../wp-content/uploads/2019/01/Senior-Design-ISEC2017-FINAL.pdf">CCNY Joint Senior Design Program in Assistive Technology Across the Department Boundaries</a><em>, The 2017 IEEE Integrated STEM Education Conference (ISEC’17),</em>Princeton, New Jersey, March 11, 2017</p>



<p>J. Gong, C. Feeley, H. Tang, G. Olmschenk, V. Nair, Y. Yu, Z. Zhou, K. Yamamoto, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Smart_Transportation_Hub_TRB2017_Final-11-14.pdf">Building Smart Transportation Hubs with Internet of Things to Improve Services to People with Special Needs</a><em>, Transportation Research Board (TRB) 96th Annual Meeting,</em>January 8-12, 2017</p>



<h2 class="wp-block-heading">2016</h2>



<p>F. Hu, N. Tsering, H. Tang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Indoor_Localization_for_the_Visually_Impaired_Using_a_3D_Sensor.pdf">Indoor Localization for the Visually Impaired Using a 3D Sensor</a><em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;V4, 2016</p>



<p>C. Tsangouri, W. Li, Z. Zhu, F. Abtahi, and T. Ro,&nbsp;<a href="../wp-content/uploads/2019/01/EmoTrain_MIT_Final.pdf">An Interactive Facial-Expression Training Platform for Individuals with Autism Spectrum Disorder</a><em>, 2016 IEEE MIT Undergraduate Research Technology Conference (URTC),</em>&nbsp;MIT, Cambridge USA , November 4-6, 2016 , ((in the top 6 nominations for Best Paper Award from the reviewers, CT’s oral presentation was voted Best Presentation in the machine learning/cloud computing track from the audience. WL and FA: PhD student mentors; ZZ and TR: faculty advisors) )</p>



<p>M. Vincent, H. Tang, W. Khoo, Z. Zhu, and T. Ro,&nbsp;<a href="https://rolab.ws.gc.cuny.edu/files/2018/09/Vincent16.pdf">Shape Discrimination using the Tongue: Implications for a Visual-to-Tactile Sensory Substitution Device</a>&nbsp;<em>, Multisensory Research,</em>29(8), 2016 , 773-798 , (<a href="http://dx.doi.org/10.1163/22134808-00002542">DOI</a>&nbsp;)</p>



<p>H. Tang, N. Tsering, F. Hu, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Automatic_Pre-Journey_Indoor_Map_Generation_Using_AutoCAD_Floor_Plan.pdf">Automatic Pre-Journey Indoor Map Generation Using AutoCAD Floor Plan</a><em>, Journal on Technology and Persons with Disabilities,</em>&nbsp;V4, 2016</p>



<p>W. Li, F. Abtahi, C. Tsangouri, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/GaMo-cvprws_compressed.pdf">Towards an &#8220;In-the-Wild&#8221; Emotion Dataset Using a Game-based Framework</a><em>, In Affect in the Wild Workshop, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR’16) Workshops ,</em>&nbsp;2016</p>



<p>W. Khoo, and Z. Zhu,&nbsp;Multimodal and Alternative Perception for the Visually Impaired: A Survey&nbsp;<em>, Journal of Assistive Technologies,</em>&nbsp;10(1), 2016 , 11-26 , (&nbsp;<a href="http://dx.doi.org/10.1108/JAT-04-2015-0014">DOI</a>&nbsp;)</p>



<p>Z. Zhu, W. Khoo, C. Santistevan, Y. Gosser, E. Molina, H. Tang, T. Ro, and Y. Tian,&nbsp;<a href="../wp-content/uploads/2019/01/isec_2016_rem_ccny-revision-final.pdf">EFRI-REM at CCNY: Research Experience and Mentoring for Underrepresented Groups in Cross-disciplinary Research on Assistive Technology</a><em>, The 6th IEEE Integrated STEM Education Conference (ISEC’16), ,</em>&nbsp;Princeton, New Jersey, March 6, 2016 , (one of the 5 H. Robert Schroeder Best Paper Award Nominees among 50 oral papers )</p>



<p>C. Lin, Z. Zhu, and T. Ro,&nbsp;<a href="../wp-content/uploads/2019/01/p274-lin.pdf">Dynamic Project-based STEM Curriculum Model for a Small Humanities High School</a><em>, The 2016 IEEE Integrated STEM Education Conference (ISEC’17), ,</em>&nbsp;Princeton, New Jersey, March 11, 2016</p>



<h2 class="wp-block-heading">2015</h2>



<p>W. Li, F. Abtahi, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/emopaper_camready-final.pdf">A deep feature based multi-kernel learning approach for video emotion recognition</a><em>, Emotion Recognition in the Wild (EmotiW) Challenge 2015, the 17th ACM International Conference on Multimodal Interaction (ICMI 2015),</em>&nbsp;Seattle, USA. November 9-13th, 2015 , ((Top 5 in terms of performance among 60 submissions) )</p>



<p>E. Molina, W. Khoo, F. Palmer, L. Ai, T. Ro, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/uic-2015-vista-poster-4p-final.pdf">Vista Wearable: Seeing through Whole-Body Touch without Contact</a><em>, The 12th IEEE International Conference on Ubiquitous Intelligence and Computing (UIC 2015),</em>&nbsp;Beijing, China, August 10-14, 2015</p>



<p>G. Olmschenk, C. Yang, Z. Zhu, H. Tong, and W. Seiple,&nbsp;<a href="../wp-content/uploads/2019/01/uic-40-mobile-crowd-assisted-final.pdf">Mobile Crowd Assisted Navigation for the Visually Impaired</a><em>, The 12th IEEE International Conference on Ubiquitous Intelligence and Computing (UIC 2015),</em>&nbsp;Beijing, China, August 10-14, 2015</p>



<p>W. Khoo, G. Olmschenk, Z. Zhu, and T. Ro,&nbsp;<a href="../wp-content/uploads/2019/01/CrowdNav-Final-Application-Track.pdf">Evaluating Crowd Sourced Navigation for the Visually Impaired in a Virtual Environment</a><em>, IEEE 4th International Conference on Mobile Services (MS 2015),</em>&nbsp;New York, NY, June 27 &#8211; July 2, 2015</p>



<p>F. Abtahi, W. Li, Z. Zhu, and T. Ro,&nbsp;Multimodal Speaker Recognition using Deep Belief Networks&nbsp;<em>, CVPR Women in Computer Vision Workshop,</em>&nbsp;2015</p>



<p>W. Li, Z. Su, M. Li, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/CNNExpRecog-MVA15_0029_Final.pdf">A Deep-Learning Approach to Facial Expression Recognition with Candid Images</a><em>, The 14th IAPR Conference on Machine Vision Applications (MVA 2015),</em>&nbsp;Tokyo, Japan, May 18-22, 2015</p>



<p>G. Olmschenk, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/corridor-paper-mva.pdf">Mobile Real-Time Single Image 3D Corridor Reconstruction Using J-Linkage</a><em>, The 14th IAPR Conference on Machine Vision Applications (MVA 2015),</em>Tokyo, May 18-22, 2015</p>



<p>F. Abtahi, A. Burry, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/MVA15_Farnaz_Final.pdf">A Deep Reinforcement Learning Approach to Character Segmentation of License Plate Images</a><em>, The 14th IAPR Conference on Machine Vision Applications (MVA 2015),</em>&nbsp;Tokyo, May 18-22, 2015</p>



<p>J. Wei, C. Liu, Z. Zhu, K. Vongsy, and O. Mendoza-schrock,&nbsp;<a href="../wp-content/uploads/2019/01/diff_surface-final.pdf">Engine Classification Using Vibrations Measured by Laser Doppler Vibrometer on Different Surfaces</a><em>, Proc. SPIE 9474, Signal Processing, Sensor/Information Fusion, and Target Recognition XXIV, 947419,</em>&nbsp;2015 , (<a href="http://dx.doi.org/10.1117/12.2179278">DOI</a>&nbsp;)</p>



<p>J. Wei, C. Liu, Z. Zhu, O. Mendoza-schrock, and K. Vongsy,&nbsp;<a href="../wp-content/uploads/2019/01/moving_vehicle_ldv-final.pdf">Classification of Uncooperative Vehicles with Sparse Laser Doppler Vibrometry Measurements</a><em>, Proc. SPIE 9464, Ground/Air Multisensor Interoperability, Integration, and Networking for Persistent ISR VI, 94640Y,</em>&nbsp;2015 , (<a href="http://dx.doi.org/10.1117/12.2179277">DOI</a>&nbsp;)</p>



<h2 class="wp-block-heading">2014</h2>



<p>E. Molina, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/tip2013-final-double.pdf">Persistent Aerial Video Registration and Fast Multi-view Mosaicing</a><em>, IEEE Transactions on Image Processing,</em>&nbsp;23, no. 5, 2014 , 2184-2192 , (<a href="http://dx.doi.org/10.1109/TIP.2014.2313183">DOI</a>&nbsp;)</p>



<p>Z Zhu, T Ro, L Ai, W Khoo, E Molina, F Palmer, <a href="https://patents.google.com/patent/US20140184384A1/en">Wearable navigation assistance for the vision-impaired</a>, <em>US Patent App. 14/141,742</em>, 2014</p>



<p>F. Hu, Z. Zhu, and J. Zhang,&nbsp;<a href="../wp-content/uploads/2019/01/W22-29.pdf">Mobile Panoramic Vision for Assisting the Blind via Indexing and Localization</a><em>, Second Workshop on Assistive Computer Vision and Robotics, in conjunction with ECCV2014,</em>&nbsp;Zurich, Switzerland, Sept 12, 2014</p>



<p>W. Li, X. Zhang, M. Goldberg, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/ECCV-2014-W22-11.pdf">Face Recognition by 3D Registration for the Visually Impaired Using a RGB-D Sensor</a><em>, Second Workshop on Assistive Computer Vision and Robotics, in conjunction with ECCV2014,</em>&nbsp;Zurich, Switzerland, Sept 12, 2014</p>



<p>T. Wang, ,&nbsp;An Adaptive and Integrated Multimodal Sensing And Processing Framework For Long-Range Moving Object Detection And Classification&nbsp;<em>, Electronic Letters on Computer Vision and Image Analysis,</em>&nbsp;Vol 13, No 2 (2014), 2014 , (<a href="http://elcvia.cvc.uab.es/article/view/613">link</a>&nbsp;)</p>



<p>G. Olmschenk, and Z. Zhu,&nbsp;3D Hallway Modeling Using A Single Image&nbsp;<em>, The Fourth IEEE Workshop on Mobile Vision, in conjunction with CVPR2014,</em>&nbsp;Columbus, Ohio, June 23, 2014 , (<a href="http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W03/papers/Olmschenk_3D_Hallway_Modeling_2014_CVPR_paper.pdf">PDF</a>&nbsp;)</p>



<p>T. Wang, R. Hammoud, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/2014-021_Wang-Hammoud_camera_ready_final.pdf">Ground-Based Activity Recognition at Distance and Behind Wall</a><em>, The 10th IEEE Workshop on Perception Beyond the Visible Spectrum (PBVS), in conjunction with CVPR 2014,</em>&nbsp;Columbus, Ohio, June 23, 2014 , (<a href="http://www.cv-foundation.org/openaccess/content_cvpr_workshops_2014/W04/papers/Wang_Ground-Based_Activity_Recognition_2014_CVPR_paper.pdf">PDF</a>&nbsp;)</p>



<h2 class="wp-block-heading">2013</h2>



<p>H. Tang, T. Ro, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/ICME13_Camera.pdf">Smart Sampling And Transducing 3d Scenes For The Visually Impaired</a><em>, IEEE International Conference on Multimedia and Expo,</em>&nbsp;San Jose, California, July 15-19, 2013</p>



<p>H. Tang, M. Vincent, T. Ro, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/MAP4VIP-HaoTang.pdf">From RGB-D to Low-Resolution Tactile: Smart Sampling And Early Testing</a><em>, IEEE Workshop on Multimodal and Alternative Perception for Visually Impaired People (MAP4VIP), in conjunction with IEEE International Conference on Multimedia and Expo,</em>&nbsp;San Jose, California, July 15-19, 2013</p>



<p>A. Diallo, E. Molina, M. Goldberg, and Z. Zhu,&nbsp;Using Kinect to Empower Visually Impaired People to Navigate Unfamiliar Environments&nbsp;<em>, 4th IEEE International Workshop on Hot Topics in 3D &#8211; Hot3D,</em>&nbsp;San Jose, California, July 15-19, 2013</p>



<p>T. Wang, Z. Zhu, and C. Taylor,&nbsp;A Multimodal Temporal Panorama Approach for Moving Vehicle Detection, Reconstruction and Classification, Computer Vision and Image Understanding&nbsp;<em>, Special Issue on Machine Vision Beyond Visible Spectrum,</em>&nbsp;June, 2013 , (<a href="http://dx.doi.org/10.1016/j.cviu.2013.02.011">http://dx.doi.org/10.1016/j.cviu.2013.02.011</a>&nbsp;)</p>



<p>T. Wang, Z. Zhu, and R. Hammoud,&nbsp;<a href="../wp-content/uploads/2019/01/cvpr13_PBVS_camReady_final-zz.pdf">Audio-Visual Feature Fusion for Vehicles Classification in a Surveillance System</a><em>, 9th IEEE Workshop on Perception Beyond the Visible Spectrum (PBVS), in conjunction with CVPR 2013,</em>&nbsp;Portland, Oregon, 2013</p>



<p>E. Molina, A. Diallo, and Z. Zhu,&nbsp;Visual Noun Navigation Framework for the Blind&nbsp;<em>, Journal of Assistive Technologies,</em>&nbsp;7(2), Emerald Group Publishing Limited, 2013 , (<a href="http://dx.doi.org/10.1108/17549451311328790">http://dx.doi.org/10.1108/17549451311328790</a>&nbsp;)</p>



<p>W. Khoo, J. Knapp, F. Palmer, T. Ro, and Z. Zhu,&nbsp;Designing and Testing Wearable Range-Vibrotactile Devices&nbsp;<em>, Journal of Assistive Technologies,</em>&nbsp;7(2), Emerald Group Publishing Limited, 2013 , (<a href="http://dx.doi.org/10.1108/17549451311328781">http://dx.doi.org/10.1108/17549451311328781</a>&nbsp;)</p>



<p>T. Wang, and Z. Zhu,&nbsp;Vision-Aided Automated Vibrometry for Remote Audio-Visual-Range Sensing&nbsp;<em>, Smart Sensors for Industrial Applications,</em>&nbsp;14 (97), K. Iniewski and M. Syrzycki, 2013</p>



<h2 class="wp-block-heading">2012</h2>



<p>T. Wang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/avss-PID2411365.pdf">Multimodal and Multi-task Audio-Visual Vehicle Detection and Classification</a><em>, IEEE International Conference on Advanced Video and Signal Based Surveillance,</em>&nbsp;Beijing, China, September 18-21, 2012 , 440-446</p>



<p>F. Palmer, Z. Zhu, and T. Ro,&nbsp;Wearable Range-Vibrotactile Field: Design and Evaluation&nbsp;<em>, 13th International Conference on Computers Helping People with Special Needs,</em>&nbsp;Springer Berlin Heidelberg, Linz, Austria, July 11-13, 2012 , 125-132</p>



<p>H. Tang, and Z. Zhu,&nbsp;A Segmentation-based Stereovision Approach for Assisting Visually Impaired People&nbsp;<em>, 13th International Conference on Computers Helping People with Special Needs,</em>&nbsp;Springer Berlin Heidelberg, Linz, Austria, July 11-13, 2012 , 581-587</p>



<p>E. Molina, Z. Zhu, and Y. Tian,&nbsp;Visual Nouns for Indoor/Outdoor Navigation&nbsp;<em>, 13th International Conference on Computers Helping People with Special Needs,</em>&nbsp;Springer Berlin Heidelberg, Linz, Austria, July 11-13, 2012 , 33-40</p>



<p>W. Khoo, E. Seidel, and Z. Zhu,&nbsp;Designing a Virtual Environment to Evaluate Multimodal Sensors for Assisting the Visually Impaired&nbsp;<em>, 13th International Conference on Computers Helping People with Special Needs,</em>&nbsp;7383, Miesenberger, Klaus and Karshmer, Arthur and Penaz, Petr and Zagler, Wolfgang, Springer Berlin Heidelberg, Linz, Austria, July 11-13, 2012 , 573-580</p>



<p>A. Khan, F. Moideen, W. Khoo, Z. Zhu, and J. Lopez,&nbsp;KinDetect: Kinect Detecting Objects&nbsp;<em>, 13th International Conference on Computers Helping People with Special Needs,</em>&nbsp;7383, Miesenberger, Klaus and Karshmer, Arthur and Penaz, Petr and Zagler, Wolfgang, Springer Berlin Heidelberg, Linz, Austria, July 11-13, 2012 , 588-595</p>



<p>H. Tang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/TCSVT08-Tang-Zhu.pdf">Content-Based 3D Mosaics for Representing Videos of Dynamic Urban Scenes</a><em>, IEEE Transactions on Circuits and Systems for Video Technology,</em>&nbsp;22(2), 2012 , 295-308 , (<a href="http://dx.doi.org/10.1109/TCSVT.2011.2178729">http://dx.doi.org/10.1109/TCSVT.2011.2178729</a>&nbsp;)</p>



<p>T. Wang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/wacv12_camR_Tao_Wang_1.pdf">Real time vehicle detection and reconstruction for improving classification</a><em>, IEEE Computer Society&#8217;s Workshop on Applications of Computer Vision,</em>Colorado, 2012</p>



<p>R. Li, Z. Zhu, N. Madampoulos, and L. Xie,&nbsp;Performance comparison of an all-fiber-based laser Doppler vibrometer for remote acoustical signal detection using short and long coherence length lasers&nbsp;<em>, Applied Optics,</em>&nbsp;51(21), 2012 , 5011-5018 , (<a href="http://dx.doi.org/10.1364/AO.51.005011">http://dx.doi.org/10.1364/AO.51.005011</a>&nbsp;)</p>



<h2 class="wp-block-heading">2011</h2>



<p>Y. Qu, T. Wang, and Z. Zhu,&nbsp;Vision-aided Laser Doppler Vibrometry for Remote Automatic Voice Detection&nbsp;<em>, IEEE/ASME Transactions on Mechatronics,</em>&nbsp;16(6), 2011 , 1110-1119</p>



<p>E. Molina, Z. Zhu, and C. Taylor,&nbsp;A Layered Approach for Fast Multi-view Stereo Panorama Generation&nbsp;<em>, IEEE ISM International Workshop on Video Panorama,</em>&nbsp;California, 2011 , 589-594</p>



<p>T. Wang, Z. Zhu, and C. Taylor,&nbsp;Multimodal temporal panorama for moving vehicle detection and reconstruction&nbsp;<em>, IEEE ISM International Workshop on Video Panorama,</em>&nbsp;California, 2011 , 571-576</p>



<p>R. Li, T. Wang, Z. Zhu, and W. Xiao,&nbsp;Vibration Characteristics of Various Surfaces Using an LDV for Long-Range Voice Acquisition&nbsp;<em>, IEEE Sensor Journal,</em>&nbsp;2011 , (accepted in 2011 )</p>



<p>T. Wang, R. Li, Z. Zhu, and Y. Qu,&nbsp;<a href="../wp-content/uploads/2019/01/wang_wacv11_final_exp.pdf">Active Stereo Vision for Improving Long Range Hearing Using a Laser Doppler Vibrometer</a><em>, IEEE Computer Society&#8217;s Workshop on Applications of Computer Vision (WACV),</em>&nbsp;2011</p>



<h2 class="wp-block-heading">2010</h2>



<p>T. Wang, Z. Zhu, R. Krzaczek, and H. Rhody,&nbsp;A System Approach to Adaptive Multimodal Sensor Designs&nbsp;<em>, Machine Vision Beyond Visible Spectrum,</em>&nbsp;1(2), R. Hammond, G. Fan, R. McMillan, and K. Ikeuchi, Springer Berlin Heidelberg, 2010 , 159-176</p>



<p>Y. Qu, T. Wang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/TMECH-Paper-LDV-Final-Qu-0907.pdf">Vision-aided Laser Doppler Vibrometry for Remote Automatic Voice Detection</a><em>, IEEE/ASME Transactions on Mechatronics,</em>&nbsp;99, 2010 , 1-10</p>



<p>Y. Qu, W. Khoo, E. Molina, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/aim2010_mm3p_final.pdf">Multimodal 3D Panoramic Imaging Using a Precise Rotating Platform</a><em>, IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2010),</em>&nbsp;Montreal, July 6th &#8211; 9th, 2010</p>



<p>Y. Qu, T. Wang, and Z. Zhu,&nbsp;<a href="file:///Users/golmschenk/Documents/ccvcl_old_html/ccvcl.org/ccvcl/assets/publications/85/paper/LDV-Paper-final-revision.pdf">An Active Multimodal Sensi</a><a href="../wp-content/uploads/2019/01/LDV-Paper-final-revision.pdf">ng Platform for Remote Voice Detection</a><em>, IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM 2010),</em>&nbsp;Montreal, July 6-9, 2010</p>



<p>T. Wang, Z. Zhu, Y. Qu, and A. Divakaran,&nbsp;Long-distance audio event detection using a laser Doppler vibrometer&nbsp;<em>, SPIE Newsroom,</em>&nbsp;2010 , (http://spie.org/x40847.xml?highlight=x2420&amp;ArticleID=x40847 )</p>



<p>T. Wang, Z. Zhu, and A. Divakaran,&nbsp;<a href="file:///Users/golmschenk/Documents/ccvcl_old_html/ccvcl.org/ccvcl/assets/publications/86/paper/Wang-SPIE-2010.pdf">Long-Rang, </a><a href="../wp-content/uploads/2019/01/Wang-SPIE-2010.pdf">Audio and Audio-Visual Event Detection Using a Laser Doppler Vibrometer</a><em>, SPIE Defense, Security and Sensing: Evolutionary and Bio-Inspired Computation: Theory and Applications IV,</em>&nbsp;2010</p>



<p>E. Molina, Z. Zhu, and O. Mendoza,&nbsp;<a href="../wp-content/uploads/2019/01/molina-spie-2010.pdf">Mosaic-based 3D scene representation and rendering of circular aerial video</a><em>, SPIE Defense, Security and Sensing: Evolutionary and Bio-Inspired Computation: Theory and Applications IV,</em>&nbsp;2010</p>



<p>T. Wang, Z. Zhu, and E. Blasch,&nbsp;Bio-Inspired Adaptive Hyperspectral Imaging for Target Tracking&nbsp;<em>, IEEE Sensors Journal, Special issue on Enhancement Algorithms, Methodologies &amp; Technology for Spectral Sensing,</em>&nbsp;Volume 10, no 3, 2010 , Page 647-654 , (<a href="http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5419266">Link text</a>&nbsp;)</p>



<p>D. Karuppiah, R. Grupen, Z. Zhu, and A. Hanson,&nbsp;Automatic Resource Allocation in a Distributed Camera Network&nbsp;<em>, Machine Vision and Applications,</em>&nbsp;Volume 21, 2010 , Page 517-528 , (<a href="http://www.springerlink.com/content/074k411q644n3462/">Link text</a>&nbsp;)</p>



<p>Z. Zhu, Y. Hu, and L. Zhao,&nbsp;Gamma/X-Ray Linear Pushbroom Stereo for 3D Cargo Inspection&nbsp;<em>, Machine Vision and Applications,</em>&nbsp;Volume 21, 2010 , Page 413-425 , (<a href="http://www.springerlink.com/content/yl7m028t16l6k636/">Link text</a>&nbsp;)</p>



<h2 class="wp-block-heading">2009</h2>



<p>H. Tang, Z. Zhu, and J. Xiao,&nbsp;<a href="../wp-content/uploads/2019/01/Hao_IROS09_final.pdf">Stereovision-Based 3D Planar Surface Estimation for Wall-Climbing Robots</a><em>, IEEE/RSJ International Conference on Intelligent Robots and Systems,</em>&nbsp;St. Louis, USA, October 11-15, 2009</p>



<p>R. Kaushik, J. Xiao, W. Morris, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/IROS09_0649_MS_corrected.pdf">3D Laser Scan Registratio</a><a href="file:///Users/golmschenk/Documents/ccvcl_old_html/ccvcl.org/ccvcl/assets/publications/80/paper/IROS09_0649_MS_corrected.pdf">n of Dual-robot System using Vision</a><em>, IEEE International Conference on Intelligent Robots and Systems,</em>&nbsp;St. Louis, USA, October 11-15, 2009</p>



<p>T. Jordan, D. Stork, W. Khoo, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Fraser_Geometry.pdf">Finding Intrinsic and Extrinsic Viewing Parameters from a Single Realist Painting</a><em>, International Conference on Computer Analysis of Images and Patterns,</em>&nbsp;September 2nd &#8211; 4th, 2009</p>



<p>W. Khoo, T. Jordan, D. Stork, and Z. Zhu,&nbsp;<a href="../index.html">Reconstruction of a Three-Dimensional Tableau from a Single Realist Painting</a><em>, International Conference on Virtual Systems and Multimedia,</em>&nbsp;September 9th &#8211; 12th, 2009</p>



<p>Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/WASR_A_321191.pdf">Mobile Sensors for Security and Surveillance</a><em>, Journal of Applied Security Research,</em>&nbsp;vol 4, no 1&amp;2, the Haworth Press, January, 2009 , 79–100 , (invited paper )</p>



<h2 class="wp-block-heading">2008</h2>



<p>Xiaokun Li, Zhigang Zhu, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.233.679&amp;rep=rep1&amp;type=pdf">Automatic Object Classification through Semantic Analysis</a>, <em>20th IEEE International Conference on Tools with Artificial Intelligence</em>, 3-5 Nov. 2008</p>



<p>Z. Zhu, Y. Hu, and L. Zhao,&nbsp;<a href="../wp-content/uploads/2019/01/MVA-Zhu-3DGammaRay-Final.pdf">Gamma/X-Ray Linear Pushbroom Stereo for 3D Cargo Inspection</a><em>, Machine Vision and Applications,</em>&nbsp;Online First in October, 2008 , (<a href="http://dx.doi.org/10.1007/s00138-008-0173-8">DOI link</a>&nbsp;)</p>



<p>T. Wang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Paper-AIPR08-Wang-Zhu-Final.pdf">Intelligent Multimodal and Hyperspectral Sensing for Real-Time Moving Target Tracking</a><em>, 37th IEEE Applied Imagery Pattern Recognition Workshop (AIPR&#8217;08): Multiple Image Information Extraction,</em>&nbsp;Washington DC, USA, 2008</p>



<p>H. Tang, and Z. Zhu,&nbsp;Content-based 3D Mosaics for Large-scale Dynamic Urban Scenes&nbsp;<em>, Technical Report TR-2008013,</em>&nbsp;Computer Science Department, Graduate Center, City University of New York, New York, 2008 , (<a href="http://tr.cs.gc.cuny.edu/tr/techreport.php?id=364">TR link</a>&nbsp;)</p>



<p>E. Molina, H. Tang, Z. Zhu, and O. Mendoza,&nbsp;<a href="../wp-content/uploads/2019/01/naecon2008.pdf">Mosaic-based Modeling and Rendering of Large-Scale Dynamic Scenes for Internet Applications</a><em>, National Aerospace and Electronics Conference (NAECON),</em>&nbsp;Dayton, Ohio, Jul 16-18, 2008</p>



<p>Z. Zhu, and T. Kanade,&nbsp;Editorial: Modeling and Representations of Large-Scale 3D Scenes&nbsp;<em>, International Journal of Computer Vision,</em>&nbsp;Volume 78, Numbers 2-3, July, 2008 , (<a href="http://dx.doi.org/10.1007/s11263-008-0128-6">DOI link</a>&nbsp;)</p>



<p>H. Tang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/Tang-Zhu-S3D.pdf">Exploiting Local and Global Scene Constraints in Modeling Large-Scale Dynamic 3D Scenes from Aerial Video</a><em>, Workshop on Search in 3D (S3D),</em>&nbsp;June 27, 2008 , (In conjunction with IEEE Conference on Computer Vision and Pattern Recognition, 2008 )</p>



<p>T. Wang, and Z. Zhu,&nbsp;Bio-Inspired Adaptive Hyperspectral Imaging for Target Tracking&nbsp;<em>, 2008 International Symposium on Spectral Sensing Research (ISSSR-2008),</em>&nbsp;Hoboken, NJ, June 23-27, 2008</p>



<p>Xiaoyan Li, and Zhigang Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/ECIR08-Proof.pdf">Enhancing Relevance Models with Adaptive Passage Retrieval</a><em>, 30th European Conference on Information Retrieval (ECIR 2008),</em>&nbsp;LNCS 4956, C. Macdonald et al. (Eds.), © Springer-Verlag Berlin Heidelberg, Glasgow, Scotland, March 30th &#8211; April 3rd, 2008 , pp 463–471</p>



<h2 class="wp-block-heading">2007</h2>



<p>Y. Feng, Z. Zhu, and J. Xiao,&nbsp;<a href="../wp-content/uploads/2019/01/yi-iros2007.pdf">Self-Localization of a Heterogeneous Multi-Robot Team in Constrained 3D Space</a><em>, IEEE/RSJ International Conference on Intelligent Robots and Systems,</em>&nbsp;San Diego, CA, USA, Oct 29 &#8211; Nov 2, 2007</p>



<p>Z. Zhu, G. Wolberg, and J. Layne,&nbsp;Dynamic pushbroom stereo vision for surveillance and inspection&nbsp;<em>, 3D imaging for Safety and Security,</em>&nbsp;A. Koschan, M. Pollefeys, and M. Abidi (eds.), Kluwer/Springer, August, 2007 , pp 173-200 , (&nbsp;<a href="http://www.springer.com/computer/computer+imaging/book/978-1-4020-6181-3">link to book</a>&nbsp;)</p>



<p>Z. Zhu, W. Li, E. Molina, and G. Wolberg,&nbsp;LDV Sensing and Processing for Remote Hearing in a Multimodal Surveillance System&nbsp;<em>, Multimodal Surveillance: Sensors, Algorithms and Systems,</em>&nbsp;Z. Zhu and T. S. Huang (eds), ISBN-10: 1596931841, Artech House Publisher, July, 2007 , pp 59-90</p>



<p>Z. Zhu, and T. Huang,&nbsp;(eds.)&nbsp;<em>, Multimodal Surveillance: Sensors, Algorithms and Systems,</em>ISBN-10: 1596931841, Artech House Publisher, July, 2007 , ([link to TOC] (http://www-cs.engr.ccny.cuny.edu/~zhu/MMS/MMS-Zhu-Huang.html) )</p>



<p>Z. Zhu, and Y. Hu,&nbsp;<a href="../wp-content/uploads/2019/01/Zhu-Z-3DGammaRay.pdf">Stereo Matching and 3D Visualization for Gamma-Ray Cargo Inspection</a><em>, Proceedings of the Eighth IEEE Workshop on Applications of Computer Vision (WACV&#8217;07),</em>Austin, Texas, USA, Feb 21st-22nd, 2007</p>



<h2 class="wp-block-heading">2006</h2>



<p>Z. Zhu, and A. Hanson,&nbsp;Mosaic-based 3D scene representation and rendering&nbsp;<em>, Signal Processing: Image Communication,</em>&nbsp;Special Issue on Interactive Representation of Still and Dynamic Scenes, Elsevier, vol 21, no 6, Elsevier B.V., October, 2006 , pp 739-754 , ([DOI link] (http://dx.doi.org/10.1016/j.image.2006.08.002) )</p>



<p>Y. Feng, Z. Zhu, and J. Xiao,&nbsp;<a href="../wp-content/uploads/2019/01/Yi-IROS2006.pdf">Heterogeneous Multi-Robot Localization in Unknown 3D Space</a><em>, the 2006 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS&#8217;06),</em>Beijing, China, October 9-15, 2006</p>



<p>W. Li, Z. Zhu, T. Huang, and M. Liu,&nbsp;<a href="../wp-content/uploads/2019/01/ICPR06-LDV-CUNY.pdf">LDV Remote Voice Acquisition and Enhancement</a><em>, Proceedings of the 18th International Conference on Pattern Recognition (ICPR’06),</em>&nbsp;Volume 04, Hong Kong, China, August 20-24, 2006 , pp 262 &#8211; 265</p>



<p>W. Li, H. Tang, C. Mckittrick, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/ICME06-VC-Camera-Ready-Final-2.pdf">Classroom Multimedia Integration</a><em>, IEEE International Conference on Multimedia &amp; Expo (ICME),</em>&nbsp;Toronto, Canada, July 9-12, 2006</p>



<p>W. Li, Z. Zhu, and G. Wolberg,&nbsp;<a href="../wp-content/uploads/2019/01/ICME06-LDV-Camera-Ready-Final-2.pdf">Remote Voice Acquisition in Multimodal Surveillance</a><em>, IEEE International Conference on Multimedia &amp; Expo (ICME),</em>&nbsp;Toronto, Canada, July 9-12, 2006 , (oral presentation, acceptance rate 22% )</p>



<p>H. Tang, Z. Zhu, G. Wolberg, and J. Layne,&nbsp;<a href="../wp-content/uploads/2019/01/Tang-3DPVT06-Final.pdf">Dynamic 3D Urban Scene Modeling Using Multiple Pushbroom Mosaics</a><em>, the Third International Symposium on 3D Data Processing, Visualization and Transmission (3DPVT 2006),</em>&nbsp;University of North Carolina, Chapel Hill, USA, June 14-16, 2006</p>



<p>W. Li, T. Huang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/procams2006_li_w.pdf">Vision-Based Projection-Handwriting Integration in Classroom</a><em>, IEEE International Workshop on Projector-Camera Systems (PROCAMS’06),</em>&nbsp;New York City, June 17, 2006 , (in conjunction with CVPR 2006 )</p>



<p>Z. Zhu, and H. Tang,&nbsp;<a href="../wp-content/uploads/2019/01/3DCINE06_Zhu_Z.pdf">Content-Based Dynamic 3D Mosaics</a><em>, IEEE Workshop on Three-Dimensional Cinematography (3DCINE&#8217;06),</em>&nbsp;New York City, June 22, 2006 , ( in conjunction with CVPR 2006 )</p>



<p>Z. Zhu, H. Tang, G. Wolberg, and J. Layne,&nbsp;<a href="../wp-content/uploads/2019/01/SPIE2006-Zhu-CB3M.pdf">Content-Based 3D Mosaics for Dynamic Urban 3D Scenes</a><em>, SPIE Defense and Security Symposium,</em>&nbsp;Orlando, Florida, USA, April 17 &#8211; 21, 2006 , ([feature article] (http://dx.doi.org/10.1117/2.1200607.0295) based on this paper was selected into SPIE Newsroom )</p>



<p>Z. Zhu, and Y. Hu,&nbsp;<a href="../wp-content/uploads/2019/01/SPIE2006-Zhu-CargoInspection-paper.pdf">Gamma/X-Ray Linear Pushbroom Stereo for 3D Cargo Inspection</a><em>, SPIE Defense and Security Symposium,</em>&nbsp;Orlando, Florida, USA, April 17 &#8211; 21, 2006</p>



<p>Z. Zhu, G. Xu, E. Riseman, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/ZhuIVC-Rev-2005.pdf">Fast Construction of Dynamic and Multi-Resolution 360° Panoramas from Video Sequences</a><em>, Image and Vision Computing Journal,</em>Volume 24, Issue 1, January, 2006 , pp 13-26</p>



<h2 class="wp-block-heading">2005</h2>



<p>Z. Zhu, H. Tang, G. Wolberg, and J. Layne,&nbsp;<a href="../wp-content/uploads/2019/01/aipr2005_zhu_zhigang.pdf">Content-Based 3D Mosaic Representation for Video of Dynamic 3D Scenes</a><em>, Proceedings 34th IEEE Applied Imagery and Pattern Recognition Workshop(AIPR&#8217;05): Multi-Modal Imaging,</em>&nbsp;Washington DC, USA, October 19-21, 2005</p>



<p>Z. Zhu, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/ICIP05_Zhu_Hanson-new-fmt.pdf">Mosaic-Based 3D Scene Representation and Rendering</a><em>, the Eleventh IEEE International Conference on Image Processing (ICIP 2005),</em>&nbsp;Genova, Italy, September 11-14, 2005 , pp I-633 -636</p>



<p>Z. Zhu, E. Riseman, A. Hanson, and H. Schultz,&nbsp;<a href="../wp-content/uploads/2019/01/fulltext.pdf">An Efficient Method for Geo-Referenced Video Mosaicing for Environmental Monitoring</a><em>, Machine Vision Applications Journal,</em>&nbsp;16(4), September, 2005 , pp 203-126 , ([DOI link] (http://dx.doi.org/10.1007/s00138-005-0173-x) )</p>



<p>Z. Zhu, H. Tang, B. Shen, and G. Wolberg,&nbsp;<a href="../wp-content/uploads/2019/01/A3DISS2005-Zhu-W15.pdf">3D and Moving Target Extraction from Dynamic Pushbroom Stereo Mosaics</a><em>, IEEE Workshop on Advanced 3D Imaging for Safety and Security,</em>&nbsp;San Diego, CA, USA, June 25, 2005</p>



<p>Z. Zhu, L. Zhao, and J. Lei,&nbsp;<a href="../wp-content/uploads/2019/01/A3DISS2005-Zhu-W17.pdf">3D Measurements in Cargo Inspection with a Gamma-Ray Linear Pushbroom Stereo System</a><em>, IEEE Workshop on Advanced 3D Imaging for Safety and Security,</em>&nbsp;San Diego, CA, USA, June 25, 2005</p>



<p>Z. Zhu, W. Li, and G. Wolberg,&nbsp;<a href="../wp-content/uploads/2019/01/OTCBVS2005-LDV-final.pdf">Integrating LDV audio and IR video for remote multimodal surveillance</a><em>, The 2nd Joint IEEE International Workshop on Object Tracking and Classification in and Beyond the Visible Spectrum (OTCBVS&#8217;05),</em>&nbsp;San Diego, CA, US, June 20, 2005</p>



<p>Z. Zhu, G. Xu, and X. Lin,&nbsp;<a href="../wp-content/uploads/2019/01/Zhu_IJCV_GFOD.pdf">Efficient Fourier-Based Approach for Detecting Orientations and Occlusions in Epipolar Plane Images for 3D Scene Modeling</a><em>, International Journal of Computer Vision,</em>&nbsp;61 (3), Kluwer Academic Publishers, February /March, 2005 , pp 233-258</p>



<h2 class="wp-block-heading">2004</h2>



<p>Z. Zhu, D. Karuppiah, E. Riseman, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/zhuRAM2003.pdf">Keep Smart, Omnidirectional Eyes on You &#8211; Adaptive Panoramic Stereo Vision for Human Tracking with Cooperative Mobile Robots</a><em>, Robotics and Automation Magazine,</em>&nbsp;Special Issue on Panoramic Robots, vol. 14, no 11, December, 2004 , pp 69-78</p>



<p>Z. Zhu, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/Zhu_CVIU_LAMP.pdf">LAMP: 3D Layered, Adaptive-resolution and Multi-perspective Panorama &#8211; a New Scene Representation</a><em>, Computer Vision and Image Understanding,</em>Special Issue on Model-based and Image-based 3D Scene Representation for Interactive Visualization, Volume 96, Issue 3, December, 2004 , pp 294-326</p>



<p>Z. Zhu, E. Riseman, A. Hanson, and D. Karuppiah,&nbsp;<a href="../wp-content/uploads/2019/01/CVIU_PanoStereo_Zhu.pdf">Dynam</a><a href="file:///Users/golmschenk/Documents/ccvcl_old_html/ccvcl.org/ccvcl/assets/publications/38/paper/CVIU_PanoStereo_Zhu.pdf">ic Mutual Calibration and View Planning for Cooperative Mobile Robots with Panoramic Virtual Stereo Vision</a><em>, Computer Vision and Image Understanding,</em>&nbsp;95 (3), September, 2004 , pp 261-286 , (vol. 26, no. 2, Feb 2004, pp 226-237. )</p>



<p>Z. Zhu, C. Mckittrick, and W. Li,&nbsp;<a href="../wp-content/uploads/2019/01/MDDE04-ZML-Final.pdf">Virtualized Classroom – automated production, media integration and user-customized presentation</a><em>, The 4th Int. Workshop on Multimedia Data and Document Engineering (with CVPR’04),</em>&nbsp;Washington DC, USA, July 2, 2004</p>



<p>E. Riseman, Z. Zhu, W. Adrion, and J. Kurose,&nbsp;The Multimedia Virtual Classroom – Developing and Evaluating A Constructivist Learning Environment&nbsp;<em>, Fifth International Conference on Information Communication Technologies in Education,</em>&nbsp;Samos Island, Greece, July 1-3, 2004</p>



<p>W. Li, H. Tang, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/IVR04-LTZ-extended.pdf">Automated registration of high-resolution images from slide presentations and whiteboard handwritings via a low-cost digital video camera</a><em>, The 2nd IEEE Workshop on Image and Video Registration (with CVPR’04),</em>&nbsp;Washington DC, USA, July 2, 2004</p>



<p>Z. Zhu, E. Riseman, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/tpami117016.pdf">Generalized Parallel-Perspective Stereo Mosaics from Airborne Videos</a><em>, IEEE Transactions on Pattern Analysis and Machine Intelligence,</em>&nbsp;vol. 26, no. 2, February, 2004 , pp 226-237</p>



<h2 class="wp-block-heading">2003</h2>



<p>Z. Zhu, ,&nbsp;<a href="../wp-content/uploads/2019/01/AIPR0344_Zhu_Z.pdf">Stereo Mosaics with Slant Parallel Projections from Many Cameras or a Moving Camera</a><em>, IEEE AIPR 2003: Imagery and Data Fusion,</em>&nbsp;Washington, DC, October 15-17, 2003</p>



<p>Z. Zhu, A. Hanson, H. Schultz, and E. Riseman,&nbsp;<a href="../wp-content/uploads/2019/01/vr-zhu.pdf">Generation and error characteristics of parallel-perspective stereo mosaics from real video</a><em>, Video Registration,,</em>&nbsp;Mubarak Shah and Rakesh Kumar (Eds.), Video Computing Series, Kluwer Academic Publisher, Boston, , May, 2003 , pp 72-105</p>



<h2 class="wp-block-heading">2002</h2>



<p>P. Dickson, J. Li, Z. Zhu, A. Hanson, E. Riseman, H. Sabrin, H. Schultz, and G. Whitten,<a href="../wp-content/uploads/2019/01/WACV02.pdf">Mosaic generation for under-vehicle inspection</a><em>, IEEE Workshop on Applications of Computer Vision,</em>&nbsp;Orlando, Florida, Dec 3-4, 2002</p>



<p>A. Fagg, S. Ou, T. Hedges, M. Brewer, M. Piantedosi, A. Hanson, P. Amstutz, Z. Zhu, and R. Grupen,&nbsp;<a href="../wp-content/uploads/2019/01/wihave02.pdf">Human-robot interaction through a distributed virtual environment</a><em>, Workshop on Intelligent Human Augmentation and Virtual Environments,</em>&nbsp;Chapel Hill, NC, October 17-19, 2002</p>



<h2 class="wp-block-heading">2001</h2>



<p>Z. Zhu, ,&nbsp;Full View Spatio-Temporal Visual Navigation &#8211; Imaging, Modeling and Representation of Real Scenes&nbsp;<em>, First Hundred National Excellent Doctorate Dissertations Series.,</em>&nbsp;Higher Education Press, Beijing, China, 2001 , (<a href="http://www-cs.engr.ccny.cuny.edu/~zhu/PhD-Thesis/">Link</a>&nbsp;)</p>



<p>J. Jin, Z. Zhu, and G. Xu,&nbsp;Digital Video Sequence Stabilization Based on 2.5D Motion Estimation and Inertial Motion Filtering&nbsp;<em>, Real-Time Imaging,</em>&nbsp;Vol. 7, No. 4, Academic Press, August, 2001 , pp. 357-365</p>



<p>Z. Zhu, ,&nbsp;<a href="../wp-content/uploads/2019/01/zOmniStereo01.pdf">Omnidirectional stereo vision</a><em>, Workshop on Omnidirectional Vision Applied to Robotic Orientation and Nondestructive Testing (NDT),</em>&nbsp;The 10th IEEE International Conference on Advanced Robotics, Budapest, Hungary, August 22-25, 2001 , (invited talk )</p>



<p>Z. Zhu, E. Riseman, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/PRISM_ICCV01.pdf">Parallel-perspective stereo mosaics</a><em>, The Eighth IEEE International Conference on Computer Vision,</em>&nbsp;Vancouver, Canada, July, 2001 , vol. I, pp 345-352</p>



<p>Z. Zhu, and A. Hanson,&nbsp;<a href="../wp-content/uploads/2019/01/LAMP_ICCV01.pdf">3D LAMP: a New Layered Panoramic Representation</a><em>, The Eighth IEEE International Conference on Computer Vision,</em>&nbsp;Vancouver, Canada, July, 2001 , vol. II, pp 723-730</p>



<p>Z. Zhu, A. Hanson, H. Schultz, and E. Riseman,&nbsp;<a href="../wp-content/uploads/2019/01/zhuVideoReg2001.pdf">Error characteristics of parallel-perspective stereo mosaics</a><em>, IEEE Workshop on Video Registration (with ICCV&#8217;01),</em>&nbsp;Vancouver, Canada, July 13, 2001</p>



<p>D. Karuppiah, Z. Zhu, and P. Shenoy,&nbsp;<a href="../wp-content/uploads/2019/01/icvs2001.pdf">A Fault-tolerant distributed vision system architecture for object tracking in a smart room</a><em>, IEEE Second International Workshop on Computer Vision Systems (with ICCV’01),</em>&nbsp;Springer Lecture Notes in Computer Science 2095, B. Schiele and G. Sagerer (Eds.), Vancouver, Canada, July 7-8, 2001 , pp 201-219</p>



<p>Z. Zhu, A. Hanson, H. Bassali, H. Schultz, and E. Riseman,&nbsp;<a href="../index.html">Generating Seamless Stereo Mosaics from Aerial Video</a><em>, ASPRS 18th Biennial Workshop on Color Photography &amp; Videography in Resource Assessment,</em>&nbsp;University of Massachusetts, Amherst, May 16-18, 2001&nbsp;<a href="../wp-content/uploads/2019/01/slides.zip">[Additional Files]</a></p>



<h2 class="wp-block-heading">2000</h2>



<p>Z. Zhu, G. Xu, B. Yang, D. Shi, and X. Lin,&nbsp;<a href="../wp-content/uploads/2019/01/ivcj00.pdf">VISATRAM: A real-time vision system for automatic traffic monitoring</a><em>, Image and Vision Computing Journal,</em>&nbsp;18(10), July, 2000 , pp 781-794</p>



<p>Z. Zhu, K. Rajasekar, E. Riseman, and A. Hanson,&nbsp;<a href="../index.html">Panoramic virtual stereo vision of cooperative mobile robots for localizing 3D moving objects</a><em>, IEEE Workshop on Omnidirectional Vision,</em>&nbsp;Hilton Head Island, June 12, 2000 , pp. 29-36 , (In conjunction with IEEE Conference on Computer Vision and Pattern Recognition, 2000 )</p>



<p>D. Karuppiah, P. Deegan, E. Araujo, Y. Yang, G. Holness, Z. Zhu, B. Lerner, R. Grupen, and E. Riseman,&nbsp;<a href="../wp-content/uploads/2019/01/wsas2000.pdf">Software Mode Changes for Continuous Motion Tracking</a><em>, Proceedings of the International Workshop on Self Adaptive Software,</em>&nbsp;Oxford, UK, April 17-19, 2000</p>



<p>J. Jin, Z. Zhu, and G. Xu,&nbsp;A Stable Vision System for Moving Vehicles&nbsp;<em>, IEEE Transactions on Intelligent Transportation Systems,</em>&nbsp;vol. 1, no. 1 , March, 2000 , pp 32-39</p>



<h2 class="wp-block-heading">1999</h2>



<p>Z. Zhu, A. Hanson, H. Schultz, E. Riseman, and F. Stolle,&nbsp;<a href="../index.html">Stereo Mosaics from a Moving Video Camera for Environmental Monitoring</a><em>, First International Workshop on Digital and Computational Video,</em>&nbsp;Tampa, Florida, USA, December 10, 1999 , pp. 45-54</p>



<p>Z. Zhu, G. Xu, and X. Lin,&nbsp;<a href="../index.html">Panoramic EPI Generation and Analysis of Video from a Moving Platform with Vibration</a><em>, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,</em>&nbsp;Fort Collins, Colorado, 23-25 June, 1999 , vol 2, pp 531-537</p>



<p>Z. Zhu, G. Xu, E. Riseman, and A. Hanson,&nbsp;<a href="../index.html">Fast Generation of Dynamic and Multi-Resolution 360-degree Panorama from Video Sequences</a><em>, Proceedings of the IEEE International Conference on Multimedia Computing and Systems,</em>&nbsp;Florence, Italy, June 7-11, 1999 , vol. 1, pp 400-406</p>



<p>Z. Zhu, G. Xu, H. Luo, and Q. Wang,&nbsp;<a href="../wp-content/uploads/2019/01/00756937-VR99.pdf">Automating the Construction of Dynamic and Multi-Resolution 360( Panorama for Natural Scenes with Moving Objects</a><em>, Proceedings of the IEEE Virtual Reality Conference,</em>&nbsp;Houston, Texas, March 13-17, 1999</p>



<h2 class="wp-block-heading">1998</h2>



<p>Z. Zhu, G. Xu, Y. Yang, and J. Jin,&nbsp;<a href="../wp-content/uploads/2019/01/IV980154.pdf">Camera stabilization based on 2.5D motion estimation and inertial motion filtering</a><em>, IEEE International Conference on Intelligent Vehicles,</em>Stuttgart, Germany, Oct 28-30, 1998 , vol. 2, pp 329-334</p>



<p>Z. Zhu, S. Yang, G. Xu, X. Lin, and D. Shi,&nbsp;<a href="../wp-content/uploads/2019/01/00704310-ITIP98.pdf">Fast Road Classification and Orientation Estimation Using Omni-View Images and Neural Networks</a><em>, IEEE Transactions on Image Processing,</em>&nbsp;vol 7, no 8, August, 1998 , pp 1182-1197</p>



<p>Z. Zhu, X. Lin, D. Shi, and G. Xu,&nbsp;<a href="../index.html">A Single Camera Stereo System for Obstacle Detection</a><em>, World Multiconference on Systemics, Cybernetics and Informatics (SCI&#8217;98) /4th International Conference on Information Systems Analysis and Synthesis (ISAS&#8217;98),</em>Orlando, U.S.A., July 12-16, 1998 , vol 3, pp 230-237</p>



<p>Z. Zhu, S. Yang, D. Shi, and G. Xu,&nbsp;<a href="../index.html">Better road following by integrating omni-view images and neural nets</a><em>, 1998 World Congress on Computational Intelligence, Proceedings of IJCNN,</em>&nbsp;Anchorage, Alaska, May 4-9, 1998, 1998 , vol 2, pp 974-979</p>



<p>Z. Zhu, G. Xu, and X. Lin,&nbsp;<a href="../wp-content/uploads/2019/01/00658453-VRAIS98.pdf">Constructing 3D natural scene from video sequences with vibrating motions</a><em>, 1998 IEEE Virtual Reality Annual International Symposium (VRAIS-98),</em>March 14-18, 1998 , pp 105 – 112</p>



<h2 class="wp-block-heading">1996</h2>



<p>Z. Zhu, B. Yang, and G. Xu,&nbsp;<a href="../wp-content/uploads/2019/01/00572047-WACV96.pdf">A visual system for automatic traffic monitoring based on 2D spatio-temporal images</a><em>, Proc. IEEE Workshop on Applications of Computer Vision,</em>Sarasota, FL, Dec. 2-4, 1996 , pp. 162-167</p>



<p>Z. Zhu, H. Xi, and G. Xu,&nbsp;<a href="../wp-content/uploads/2019/01/00549162-ICNN96.pdf">Combining rotation-invariance images and neural networks for road scene understanding</a><em>, Proc. IEEE International Conference on Neural Network,</em>Washington DC, USA, June 3-6, 1996 , vol 3, pp. 1732-1737</p>



<p>X. Lin, Z. Zhu, and W. Deng,&nbsp;<a href="../wp-content/uploads/2019/01/00503866-ICRA96.pdf">A Stereo Matching Algorithm Based on Shape Similarity for Indoor Environment Model Building</a><em>, Proc. IEEE International Conference Robotics and Automation,</em>&nbsp;Minneapolis, MN, April 22-28, 1996 , vol 1, pp. 765-770</p>



<h2 class="wp-block-heading">1994</h2>



<p>Z. Zhu, G. Xu, and D. Shi,&nbsp;<a href="../wp-content/uploads/2019/01/00576425-ICPR94.pdf">Qualitative estimations of range and motion using spatio-temporal textural images</a><em>, Proc. 12th International Conference on Pattern Recognition,</em>Jerusalem, Israel, Oct. 9-13, 1994 , pp 736-738</p>



<p>Z. Zhu, G. Xu, S. Chen, and X. Lin,&nbsp;<a href="../wp-content/uploads/2019/01/00351181_ICRA94.pdf">Dynamic obstacle detection through cooperation of purposive visual modules of color stereo and motion</a><em>, Proc. IEEE International Conference on Robotics and Automation,</em>&nbsp;San Diego, May, 1994 , pp 1916-1922</p>



<h2 class="wp-block-heading">1993</h2>



<p>S. Chen, X. Lin, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/00341057-CVPR93.pdf">Qualitative visual navigation using weighted correlation</a><em>, Proc IEEE Conference on Computer Vision and Pattern Recognition,</em>&nbsp;New York, USA, June 15-17, 1993 , pp 620-624</p>



<h2 class="wp-block-heading">1990</h2>



<p>X. Lin, and Z. Zhu,&nbsp;<a href="../wp-content/uploads/2019/01/00139582-ICCV90.pdf">Detecting Height From Constrained Motion</a><em>, Proc. IEEE 3rd International Conference on Computer Vision,</em>&nbsp;Osaka, Japan, 1990 , pp 503-506</p>
</div><!-- .entry-content --></div><!-- .site-column-wrapper .clearfix --></div><!-- .site-column .site-column-content --><div class="site-column site-column-aside">

			<div class="site-column-wrapper clearfix">

				<div class="widget_text widget widget_custom_html clearfix" id="custom_html-2"><div class="textwidget custom-html-widget"><style>
.navigation li a {
	display: block;
	padding-top: 10px;
	padding-bottom: 10px;
	padding-left: 10px;
	margin-bottom: 2px;
	border: 1px solid #000000;
	border-left: 5px solid #590F6E;
	text-decoration: none;
}

.navigation {
	padding: 0px;
	margin: 0px;
	list-style: none;
}
</style>
<ul class="navigation">
<li><a href="../index.html">Home</a></li>
<li><a href="../people/index.html">People</a></li>
<li><a href="../research-projects/index.html">Research</a></li>
<li><a href="index.html">Publications</a></li>
<li><a href="../courses/index.html">Courses</a></li>
</ul></div></div><div class="widget widget_meta clearfix" id="meta-2"><p class="widget-title">Meta</p>
		<ul>
						<li><a href="../wp-login.html">Log in</a></li>
			<li><a href="../feed/index.html">Entries feed</a></li>
			<li><a href="../comments/feed/index.html">Comments feed</a></li>

			<li><a href="https://wordpress.org/">WordPress.org</a></li>
		</ul>

		</div>
			</div><!-- .site-column-wrapper .clearfix -->

		</div><!-- .site-column .site-column-aside -->
		</div><!-- .site-section-wrapper .site-section-wrapper-main -->
	</div><!-- .site-page-content -->

	
</main><!-- #site-main -->
	

		<div id="site-footer-credit">
			<div class="site-section-wrapper site-section-wrapper-footer-credit">
				<p class="site-credit">Copyright &copy; 2024 CUNY Computational Vision and Convergence Laboratory</p>
						<p class="academia-credit">Theme by <a href="https://www.academiathemes.com/" rel="nofollow designer noopener" target="_blank">AcademiaThemes</a></p>			</div><!-- .site-section-wrapper .site-section-wrapper-footer-credit -->
		</div><!-- #site-footer-credit -->

	</div><!-- .site-wrapper-all .site-wrapper-boxed -->

</div><!-- #container -->

<script type="text/javascript" src="../wp-content/themes/bradbury-custom/js/bradbury6b25.js?ver=2.1.4" id="bradbury-scripts-js"></script>
	<script>
	/(trident|msie)/i.test(navigator.userAgent)&&document.getElementById&&window.addEventListener&&window.addEventListener("hashchange",function(){var t,e=location.hash.substring(1);/^[A-z0-9_-]+$/.test(e)&&(t=document.getElementById(e))&&(/^(?:a|select|input|button|textarea)$/i.test(t.tagName)||(t.tabIndex=-1),t.focus())},!1);
	</script>
	</body>

<!-- Mirrored from ccvcl.org/publications/ by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 10 Dec 2024 23:51:44 GMT -->
</html>